---

## **Agenda**

1. **What is a Reasoning LLM?**
2. **Reasoning Models vs Traditional LLMs**
3. **Why Use a Reasoning LLM?**
4. **When to Use a Reasoning LLM?**
5. **How to Use a Reasoning LLM?**
6. **Limitations of Reasoning LLMs**
7. **Choosing a Reasoning LLM**
8. **Hands-on with Reasoning LLMs**

---

## **1. What is a Reasoning LLM?**

- **Definition**:
  - Language models designed for **complex, multi-step problems**.
  - Generate **intermediate reasoning steps** or "thought processes".
  - Break down tasks into **logical sub-steps**.
  - Similar to **human step-by-step problem solving**.
  
- **Benefits**:
  - **More accurate and explainable results** on challenging tasks.
    - **Mathematical problems**
    - **Logic puzzles**
    - **Code debugging**
  
- **Reference Quote**:  
  *"With a reasoning LLM, when you send an input to the model, the model breaks that down into a bunch of subproblems before actually solving and returning a response."*

---

## **2. Reasoning Models vs Traditional LLMs**

### **Traditional LLMs**

- **Characteristics**:
  - Direct **pattern-based prediction**.
  - One-shot "**I'm feeling lucky**" approach.
  - Quick but **less reliable on complex tasks**.
  - **No explicit reasoning steps**.
  
- **Reference Quote**:  
  *"Traditional LLMs have no explicit reasoning steps."*

### **Reasoning LLMs**

- **Characteristics**:
  - **Step-by-step problem solving**.
  - **Chain-of-thought (CoT)** approach.
  - More methodical but **slower**.
  - **Shows intermediate steps**.
  
- **Reference Quote**:  
  *"Reasoning LLMs will have step-by-step problem solving. They will fine-tune with chain-of-thought examples usually."*

---

## **3. Why Use a Reasoning LLM?**

- **Importance of Reasoning Quality**:
  - **Top criterion** when choosing an LLM.
  - Users seek models capable of solving **complex problems effectively**.
  
- **Factors Users Care About**:
  - **Reasoning Quality**
  - **Price**
  - Embedded Knowledge
  - Context Window
  - Latency
  
- **Reference Quote**:  
  *"People care about reasoning quality and price. What people tend to care about the most when they're going to use a model while people care about reasoning quality and they think they care about price."*

---

## **4. When to Use a Reasoning LLM?**

- **Ideal Scenarios**:
  - **Background tasks** where latency isn't critical.
  - **Complex problems** requiring deeper thinking.
  - Tasks benefiting from **extensive reasoning**.
  - **Research and planning-heavy workflows**.
  
- **Ideal Use Cases**:

  - ### **Complex Problem Solving**
    - Mathematical proofs
    - Logic puzzles
    - Multi-step reasoning

  - ### **Deep Analysis**
    - Research papers
    - Document analysis
    - Meeting notes interpretation

  - ### **Planning & Agency**
    - Workflow planning
    - Agentic systems
    - Strategic decision-making
  
- **Reference Quote**:  
  *"Use a reasoning LLM when you have background tasks where latency is not super critical but they are of somewhat high importance."*

---

## **5. How to Use a Reasoning LLM**

- **Prompting Techniques**:

  - **Think in Terms of Briefs, Not Prompts**:
    - **Goal**: Clearly define what you want to achieve.
    - **Return Format**: Specify how you want the response to look.
    - **Warnings/Safety**: Mention any filters or content to avoid.
    - **Context Dump**: Provide all the necessary information or documents.

  - **Reference Quote**:  
    *"Don't think about prompts when you're using a reasoning model. Think about briefs."*

- **Tips for Effective Use**:

  - **Use as Report Generators**:
    - Generate structured reports compiling extensive information.

  - **Provide Ample Context**:
    - **Leverage tools** for managing context:
      - **GitIngest** for GitHub repositories.
      - **R.Gina.ai** for websites.
    - **Include PDFs and documents** as needed.

  - **Utilize Transcription Tools**:
    - **SuperWhisper** for audio transcription to create prompts without typing.

    - **Reference Quote**:  
      *"I was just able to easily create that prompt with audio without having to actually write down everything which is super helpful to actually be able to be fast and effective with these models."*

  - **Develop Good Criteria**:
    - Clearly define **what is good vs. bad output**.
    - Helps the model to **self-evaluate and improve** its responses.

- **Model-Specific Tips**:

  - For **Claude Desktop with Extended Thinking**:
    - **Place context before** the request.

  - For **OpenAI Models**:
    - **Place context after** the request.

---

## **6. Limitations of Reasoning LLMs**

### **1. Performance Trade-offs**

- **Increased Latency**:
  - Extended thinking process leads to **longer response times**.
  
- **Higher Resource Requirements**:
  - Requires more **computational resources**.

- **Cost Implications**:
  - More tokens and processing time translate to **higher operational costs**.

- **Scalability Challenges**:
  - Multiple concurrent requests become more **resource-intensive**.

### **2. Reasoning Quality Constraints**

- **Domain-Specific Limitations**:
  - Performance **varies across different subject areas**.

- **Brittleness with Novel Problems**:
  - May struggle with **unseen problem types**.

- **Inconsistent Depth of Reasoning**:
  - Quality can **vary within the same model**.

- **Overconfidence in Incorrect Reasoning**:
  - May present **flawed reasoning with high confidence**.

- **Reference Quote**:  
  *"They might have some inconsistent depth in the reasoning... always validate if the reasoning steps are coherent with the output that's generated."*

### **3. Knowledge and Context Limitations**

- **Bounded Knowledge**:
  - Limited to **training data available** at model development time.

- **Context Window Constraints**:
  - Struggles with **very lengthy problems** despite large context windows.

- **Information Integration Challenges**:
  - Difficulty maintaining **coherence across extensive reasoning chains**.

- **Limited Transfer Learning**:
  - Reasoning in one domain doesn't always **transfer to other domains**.

- **Reference Quote**:  
  *"Because they don't reason, their ability to transfer knowledge from one domain to another is going to also be limited."*

---

## **7. Choosing a Reasoning LLM**

- **Factors to Consider**:

  - **Intelligence Score**:
    - Look for models with **high performance on benchmarks**.
    - Example: **DeepSeaCAR1**, **Gemini 2.0 Flash**.

  - **Speed/Latency**:
    - Consider **how fast the model generates tokens**.
    - Higher speed may be crucial for time-sensitive tasks.

  - **Cost**:
    - Evaluate the **price per million tokens**.
    - Balance between cost and performance.

  - **Task Requirements**:
    - **Specific needs** of your project or application.
    - Language support, domain expertise, etc.

- **Decision-Making Process**:

  - **Create a Decision Matrix**:
    - List models and score them based on factors.
    - Assign **weights** to factors based on importance.
    - Normalize scores for effective comparison.

  - **Reference Quote**:  
    *"I would at least use this as a framework to consider in general which elements to kind of put in the same box."*

- **Example Models**:

  - **DeepSeaCAR1**:
    - High intelligence score.
    - Slower speed but excellent reasoning capabilities.
    - Cost-effective for deep analytical tasks.

  - **Gemini 2.0 Flash**:
    - High speed (254 output tokens per second).
    - Competitive intelligence score.
    - Suitable for tasks requiring **both speed and reasoning**.

---

## **8. Hands-on with Reasoning LLMs**

- **Practical Demonstrations**:

  - **Using ChatGPT with Reasoning Models**:
    - Select models like **O1** for extended reasoning.
    - Example Prompt:
      - *"Plan out a to-do list app for me. Make it a simple project in Python."*

  - **Viewing Reasoning Steps**:
    - Some models allow you to **expand and view** the reasoning behind the output.
    - Helps in **validating and understanding** the model's thought process.

- **Utilizing Tools for Efficiency**:

  - **Audio Transcription with SuperWhisper**:
    - Dictate prompts instead of typing.
    - Accelerates the process of creating detailed briefs.

  - **Reference Quote**:  
    *"I was just able to easily create that prompt with audio without having to actually write down everything."*

- **Evaluating Model Performance**:

  - **Vibe Checking**:
    - Interact with models to **gauge their responsiveness** and suitability.
  
  - **Testing Across Tasks**:
    - Experiment with different problem types to see **how models handle various subjects**.

---

## **Conclusion**

- **Key Takeaways**:
  - **Reasoning LLMs** are powerful tools for complex problem-solving.
  - They require **thoughtful prompting** and **context management**.
  - Be aware of their **limitations** and **choose models** that align with your needs.
  - **Hands-on practice** is essential to fully leverage their capabilities.