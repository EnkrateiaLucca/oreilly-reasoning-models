{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extended Thinking with the Anthropic API\n",
    "\n",
    "This notebook provides a comprehensive guide to leveraging Claude's extended thinking capabilities for complex reasoning tasks. Extended thinking gives Claude enhanced reasoning capabilities while providing transparency into its step-by-step thought process.\n",
    "\n",
    "## What is Extended Thinking?\n",
    "\n",
    "Extended thinking allows Claude to:\n",
    "- Work through complex problems step-by-step\n",
    "- Show its reasoning process in `thinking` content blocks\n",
    "- Improve response quality for tasks requiring deep analysis\n",
    "- Chain multiple tool calls with reasoning steps in between"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Supported Models\n",
    "\n",
    "Extended thinking is available in:\n",
    "- **Claude Opus 4.1** (`claude-opus-4-1-20250805`)\n",
    "- **Claude Opus 4** (`claude-opus-4-20250514`)\n",
    "- **Claude Sonnet 4** (`claude-sonnet-4-20250514`)\n",
    "- **Claude Sonnet 3.7** (`claude-3-7-sonnet-20250219`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Installation\n",
    "\n",
    "First, let's install the required packages and set up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the Anthropic Python SDK\n",
    "!pip install anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import os\nimport json\nfrom anthropic import Anthropic\nfrom typing import Dict, Any, List\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file (if it exists)\nload_dotenv()\n\n# Set up your API key\n# You can either set it as an environment variable or directly here\n# Option 1: Environment variable (recommended)\n# export ANTHROPIC_API_KEY=\"your-api-key\"\n\n# Option 2: Direct assignment (only for testing)\n# api_key = \"your-api-key-here\"\n\n# Initialize the client\nclient = Anthropic(\n    # api_key=api_key  # Uncomment if not using environment variable\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Extended Thinking Example\n",
    "\n",
    "Let's start with a simple example showing how to enable extended thinking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_thinking_example():\n",
    "    \"\"\"Basic example of using extended thinking\"\"\"\n",
    "    \n",
    "    response = client.messages.create(\n",
    "        model=\"claude-opus-4-1-20250805\",\n",
    "        max_tokens=4096,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"What is the sum of the first 50 prime numbers? Walk me through your approach.\"\n",
    "            }\n",
    "        ],\n",
    "        thinking={\n",
    "            \"type\": \"enabled\",\n",
    "            \"budget_tokens\": 8192  # Allow up to 8k tokens for thinking\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Run the example\n",
    "result = basic_thinking_example()\n",
    "print(\"Response:\")\n",
    "for block in result.content:\n",
    "    if block.type == \"thinking\":\n",
    "        print(f\"\\n=== THINKING ===\\n{block.text}\\n\")\n",
    "    elif block.type == \"text\":\n",
    "        print(f\"\\n=== FINAL ANSWER ===\\n{block.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding Token Budgets\n",
    "\n",
    "The `budget_tokens` parameter determines how many tokens Claude can use for reasoning:\n",
    "- **Minimum**: 1,024 tokens\n",
    "- **Recommended starting point**: 8,192 tokens for moderate complexity\n",
    "- **Complex tasks**: 16,384+ tokens\n",
    "- **Very complex tasks**: 32,768+ tokens (consider batch processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_thinking_budgets():\n",
    "    \"\"\"Compare results with different thinking budgets\"\"\"\n",
    "    \n",
    "    problem = \"\"\"Solve this logic puzzle:\n",
    "    Three friends (Alice, Bob, Charlie) each have a different pet (cat, dog, fish) \n",
    "    and live in different colored houses (red, blue, green).\n",
    "    - The person with the cat doesn't live in the red house\n",
    "    - Bob doesn't have the fish\n",
    "    - Alice lives in the blue house\n",
    "    - The person in the green house has a dog\n",
    "    \n",
    "    Who has which pet and lives in which house?\"\"\"\n",
    "    \n",
    "    budgets = [1024, 4096, 16384]\n",
    "    results = {}\n",
    "    \n",
    "    for budget in budgets:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Testing with {budget} token budget\")\n",
    "        print('='*50)\n",
    "        \n",
    "        response = client.messages.create(\n",
    "            model=\"claude-opus-4-1-20250805\",\n",
    "            max_tokens=1024,\n",
    "            messages=[{\"role\": \"user\", \"content\": problem}],\n",
    "            thinking={\n",
    "                \"type\": \"enabled\",\n",
    "                \"budget_tokens\": budget\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Extract the final answer\n",
    "        for block in response.content:\n",
    "            if block.type == \"text\":\n",
    "                print(f\"Answer: {block.text[:200]}...\")\n",
    "                results[budget] = block.text\n",
    "                break\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Uncomment to run (will use API credits)\n",
    "# results = compare_thinking_budgets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Streaming Extended Thinking\n",
    "\n",
    "For better user experience, you can stream responses including thinking blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_thinking_example():\n",
    "    \"\"\"Example of streaming with extended thinking\"\"\"\n",
    "    \n",
    "    stream = client.messages.create(\n",
    "        model=\"claude-opus-4-1-20250805\",\n",
    "        max_tokens=2048,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Explain the quicksort algorithm and implement it in Python.\"\n",
    "            }\n",
    "        ],\n",
    "        thinking={\n",
    "            \"type\": \"enabled\",\n",
    "            \"budget_tokens\": 4096\n",
    "        },\n",
    "        stream=True\n",
    "    )\n",
    "    \n",
    "    current_block_type = None\n",
    "    \n",
    "    for event in stream:\n",
    "        if event.type == \"content_block_start\":\n",
    "            block = event.content_block\n",
    "            if block.type == \"thinking\":\n",
    "                print(\"\\n=== THINKING STARTS ===\\n\", end=\"\")\n",
    "                current_block_type = \"thinking\"\n",
    "            elif block.type == \"text\":\n",
    "                print(\"\\n=== RESPONSE STARTS ===\\n\", end=\"\")\n",
    "                current_block_type = \"text\"\n",
    "                \n",
    "        elif event.type == \"thinking_delta\":\n",
    "            print(event.delta.text, end=\"\", flush=True)\n",
    "            \n",
    "        elif event.type == \"content_block_delta\":\n",
    "            if hasattr(event.delta, 'text'):\n",
    "                print(event.delta.text, end=\"\", flush=True)\n",
    "                \n",
    "        elif event.type == \"content_block_stop\":\n",
    "            print(\"\\n\")\n",
    "\n",
    "# Uncomment to run\n",
    "# stream_thinking_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extended Thinking with Tool Use\n",
    "\n",
    "One of the powerful features is combining extended thinking with tool use. This allows Claude to reason about tool selection and results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thinking_with_tools_example():\n",
    "    \"\"\"Example combining extended thinking with tool use\"\"\"\n",
    "    \n",
    "    # Define a simple calculator tool\n",
    "    tools = [\n",
    "        {\n",
    "            \"name\": \"calculator\",\n",
    "            \"description\": \"Perform mathematical calculations\",\n",
    "            \"input_schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"expression\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"Mathematical expression to evaluate\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"expression\"]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"get_weather\",\n",
    "            \"description\": \"Get current weather for a location\",\n",
    "            \"input_schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"location\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"City name\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    response = client.messages.create(\n",
    "        model=\"claude-opus-4-1-20250805\",\n",
    "        max_tokens=2048,\n",
    "        tools=tools,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"If I have 3 apples and buy 5 more, then give away 2, how many do I have?\"\n",
    "            }\n",
    "        ],\n",
    "        thinking={\n",
    "            \"type\": \"enabled\",\n",
    "            \"budget_tokens\": 4096\n",
    "        },\n",
    "        tool_choice={\"type\": \"auto\"}  # Let Claude decide whether to use tools\n",
    "    )\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Process the response\n",
    "def process_tool_response(response):\n",
    "    \"\"\"Process a response that may contain tool use\"\"\"\n",
    "    \n",
    "    for block in response.content:\n",
    "        if block.type == \"thinking\":\n",
    "            print(f\"\\n=== THINKING ===\\n{block.text[:500]}...\\n\")\n",
    "        elif block.type == \"text\":\n",
    "            print(f\"\\n=== RESPONSE ===\\n{block.text}\")\n",
    "        elif block.type == \"tool_use\":\n",
    "            print(f\"\\n=== TOOL USE ===\\nTool: {block.name}\\nInput: {block.input}\")\n",
    "\n",
    "# Uncomment to run\n",
    "# response = thinking_with_tools_example()\n",
    "# process_tool_response(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interleaved Thinking (Claude 4 Models Only)\n",
    "\n",
    "Interleaved thinking allows Claude to think between tool calls, enabling more sophisticated multi-step reasoning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interleaved_thinking_example():\n",
    "    \"\"\"Example of interleaved thinking with multiple tool calls\"\"\"\n",
    "    \n",
    "    # This requires the beta header for interleaved thinking\n",
    "    client_with_beta = Anthropic(\n",
    "        default_headers={\n",
    "            \"anthropic-beta\": \"interleaved-thinking-2025-05-14\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    tools = [\n",
    "        {\n",
    "            \"name\": \"search_database\",\n",
    "            \"description\": \"Search for information in a database\",\n",
    "            \"input_schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\"type\": \"string\"},\n",
    "                    \"filters\": {\"type\": \"object\"}\n",
    "                },\n",
    "                \"required\": [\"query\"]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"analyze_data\",\n",
    "            \"description\": \"Analyze data and return insights\",\n",
    "            \"input_schema\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"data\": {\"type\": \"array\"},\n",
    "                    \"analysis_type\": {\"type\": \"string\"}\n",
    "                },\n",
    "                \"required\": [\"data\", \"analysis_type\"]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    response = client_with_beta.messages.create(\n",
    "        model=\"claude-opus-4-1-20250805\",\n",
    "        max_tokens=4096,\n",
    "        tools=tools,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": \"Find all customers who made purchases last month and analyze their buying patterns.\"\n",
    "            }\n",
    "        ],\n",
    "        thinking={\n",
    "            \"type\": \"enabled\",\n",
    "            \"budget_tokens\": 16384  # Larger budget for complex multi-step reasoning\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return response\n",
    "\n",
    "# Note: With interleaved thinking, Claude can:\n",
    "# 1. Think about what data to search for\n",
    "# 2. Call search_database tool\n",
    "# 3. Think about the results\n",
    "# 4. Decide to call analyze_data tool\n",
    "# 5. Think about the analysis\n",
    "# 6. Provide final insights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Multi-Turn Conversations\n",
    "\n",
    "When using extended thinking in conversations, you must preserve thinking blocks when continuing with tool results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_turn_conversation():\n",
    "    \"\"\"Example of handling multi-turn conversations with thinking\"\"\"\n",
    "    \n",
    "    messages = []\n",
    "    \n",
    "    # First turn\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"I need help planning a trip. What should I consider?\"\n",
    "    })\n",
    "    \n",
    "    response1 = client.messages.create(\n",
    "        model=\"claude-opus-4-1-20250805\",\n",
    "        max_tokens=2048,\n",
    "        messages=messages,\n",
    "        thinking={\n",
    "            \"type\": \"enabled\",\n",
    "            \"budget_tokens\": 4096\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    # Extract response for conversation history\n",
    "    # Note: Thinking blocks are automatically stripped in subsequent turns\n",
    "    assistant_message = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": []\n",
    "    }\n",
    "    \n",
    "    for block in response1.content:\n",
    "        if block.type == \"text\":\n",
    "            assistant_message[\"content\"].append({\n",
    "                \"type\": \"text\",\n",
    "                \"text\": block.text\n",
    "            })\n",
    "    \n",
    "    messages.append(assistant_message)\n",
    "    \n",
    "    # Second turn\n",
    "    messages.append({\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"I'm thinking about visiting Japan in April. What's special about that time?\"\n",
    "    })\n",
    "    \n",
    "    response2 = client.messages.create(\n",
    "        model=\"claude-opus-4-1-20250805\",\n",
    "        max_tokens=2048,\n",
    "        messages=messages,\n",
    "        thinking={\n",
    "            \"type\": \"enabled\",\n",
    "            \"budget_tokens\": 4096\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return response1, response2\n",
    "\n",
    "# Uncomment to run\n",
    "# r1, r2 = multi_turn_conversation()\n",
    "# print(\"First response:\", r1.content[-1].text[:200])\n",
    "# print(\"\\nSecond response:\", r2.content[-1].text[:200])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Practices and Tips\n",
    "\n",
    "### 1. Choosing the Right Token Budget\n",
    "\n",
    "- **Simple logic problems**: 1,024 - 4,096 tokens\n",
    "- **Moderate complexity** (multi-step math, basic coding): 4,096 - 8,192 tokens\n",
    "- **Complex tasks** (algorithm design, deep analysis): 16,384 - 32,768 tokens\n",
    "- **Very complex tasks**: 32,768+ tokens (consider batch processing)\n",
    "\n",
    "### 2. When to Use Extended Thinking\n",
    "\n",
    "Extended thinking is most beneficial for:\n",
    "- Mathematical problems requiring step-by-step calculation\n",
    "- Complex coding challenges\n",
    "- Logic puzzles and reasoning tasks\n",
    "- Multi-step analysis problems\n",
    "- Tasks requiring careful consideration of multiple factors\n",
    "\n",
    "### 3. Performance Considerations\n",
    "\n",
    "- Extended thinking increases response time\n",
    "- Streaming is required when `max_tokens` > 21,333\n",
    "- For budgets > 32k tokens, use batch processing to avoid timeouts\n",
    "\n",
    "### 4. Cost Optimization\n",
    "\n",
    "- Start with minimum budget and increase as needed\n",
    "- Monitor actual token usage vs. allocated budget\n",
    "- Claude may not use the entire budget if not needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_thinking_budget():\n",
    "    \"\"\"Helper function to find optimal thinking budget for a task\"\"\"\n",
    "    \n",
    "    def test_budget(task: str, budget: int) -> Dict[str, Any]:\n",
    "        \"\"\"Test a specific budget and return metrics\"\"\"\n",
    "        response = client.messages.create(\n",
    "            model=\"claude-opus-4-1-20250805\",\n",
    "            max_tokens=2048,\n",
    "            messages=[{\"role\": \"user\", \"content\": task}],\n",
    "            thinking={\n",
    "                \"type\": \"enabled\",\n",
    "                \"budget_tokens\": budget\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # Extract metrics from usage\n",
    "        return {\n",
    "            \"budget\": budget,\n",
    "            \"input_tokens\": response.usage.input_tokens,\n",
    "            \"output_tokens\": response.usage.output_tokens,\n",
    "            \"total_tokens\": response.usage.input_tokens + response.usage.output_tokens,\n",
    "            \"response_quality\": len(response.content[-1].text) if response.content else 0\n",
    "        }\n",
    "    \n",
    "    # Test different budgets\n",
    "    task = \"Write a function to find the nth Fibonacci number using dynamic programming\"\n",
    "    budgets = [1024, 2048, 4096, 8192]\n",
    "    \n",
    "    results = []\n",
    "    for budget in budgets:\n",
    "        print(f\"Testing budget: {budget} tokens...\")\n",
    "        metrics = test_budget(task, budget)\n",
    "        results.append(metrics)\n",
    "        print(f\"  Output tokens used: {metrics['output_tokens']}\")\n",
    "        print(f\"  Response length: {metrics['response_quality']} chars\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Uncomment to run optimization test\n",
    "# optimization_results = optimize_thinking_budget()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Common Patterns and Use Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern 1: Complex Problem Solving\n",
    "def solve_complex_problem(problem: str):\n",
    "    \"\"\"Template for solving complex problems with extended thinking\"\"\"\n",
    "    \n",
    "    return client.messages.create(\n",
    "        model=\"claude-opus-4-1-20250805\",\n",
    "        max_tokens=4096,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are an expert problem solver. Break down complex problems systematically.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": problem\n",
    "            }\n",
    "        ],\n",
    "        thinking={\n",
    "            \"type\": \"enabled\",\n",
    "            \"budget_tokens\": 16384\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Pattern 2: Code Generation with Reasoning\n",
    "def generate_code_with_reasoning(requirements: str):\n",
    "    \"\"\"Generate code with detailed reasoning about design choices\"\"\"\n",
    "    \n",
    "    return client.messages.create(\n",
    "        model=\"claude-opus-4-1-20250805\",\n",
    "        max_tokens=8192,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"Create a Python implementation for the following requirements:\n",
    "                {requirements}\n",
    "                \n",
    "                Explain your design decisions and implementation approach.\"\"\"\n",
    "            }\n",
    "        ],\n",
    "        thinking={\n",
    "            \"type\": \"enabled\",\n",
    "            \"budget_tokens\": 8192\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Pattern 3: Data Analysis with Step-by-Step Reasoning\n",
    "def analyze_data_with_reasoning(data_description: str, analysis_goal: str):\n",
    "    \"\"\"Analyze data with transparent reasoning process\"\"\"\n",
    "    \n",
    "    return client.messages.create(\n",
    "        model=\"claude-opus-4-1-20250805\",\n",
    "        max_tokens=4096,\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"\"\"Data: {data_description}\n",
    "                \n",
    "                Analysis Goal: {analysis_goal}\n",
    "                \n",
    "                Please analyze this data step by step and provide insights.\"\"\"\n",
    "            }\n",
    "        ],\n",
    "        thinking={\n",
    "            \"type\": \"enabled\",\n",
    "            \"budget_tokens\": 12288\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Handling and Edge Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_thinking_request(prompt: str, budget: int = 8192, max_retries: int = 3):\n",
    "    \"\"\"Robust wrapper for extended thinking requests with error handling\"\"\"\n",
    "    \n",
    "    import time\n",
    "    from anthropic import APIError, RateLimitError\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            response = client.messages.create(\n",
    "                model=\"claude-opus-4-1-20250805\",\n",
    "                max_tokens=min(4096, budget - 1),  # Ensure max_tokens < budget_tokens\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                thinking={\n",
    "                    \"type\": \"enabled\",\n",
    "                    \"budget_tokens\": budget\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            # Process response\n",
    "            result = {\n",
    "                \"thinking\": [],\n",
    "                \"response\": \"\",\n",
    "                \"tokens_used\": response.usage.output_tokens if hasattr(response, 'usage') else None\n",
    "            }\n",
    "            \n",
    "            for block in response.content:\n",
    "                if block.type == \"thinking\":\n",
    "                    result[\"thinking\"].append(block.text)\n",
    "                elif block.type == \"text\":\n",
    "                    result[\"response\"] = block.text\n",
    "            \n",
    "            return result\n",
    "            \n",
    "        except RateLimitError as e:\n",
    "            print(f\"Rate limit hit. Waiting {2 ** attempt} seconds...\")\n",
    "            time.sleep(2 ** attempt)\n",
    "            \n",
    "        except APIError as e:\n",
    "            print(f\"API error: {e}\")\n",
    "            if attempt == max_retries - 1:\n",
    "                raise\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Unexpected error: {e}\")\n",
    "            raise\n",
    "    \n",
    "    return None\n",
    "\n",
    "# Example usage\n",
    "# result = robust_thinking_request(\n",
    "#     \"What is the optimal algorithm for finding the shortest path in a weighted graph?\",\n",
    "#     budget=8192\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Takeaways\n",
    "\n",
    "### Key Points to Remember:\n",
    "\n",
    "1. **Extended thinking enhances Claude's reasoning** for complex tasks\n",
    "2. **Token budgets** should match task complexity (1k-32k+ tokens)\n",
    "3. **Thinking blocks are transparent** in Claude 3.7, summarized in Claude 4\n",
    "4. **Interleaved thinking** (Claude 4 only) enables reasoning between tool calls\n",
    "5. **Preserve thinking blocks** when continuing conversations with tool use\n",
    "6. **Stream responses** for better UX, especially with large budgets\n",
    "7. **Monitor token usage** to optimize costs and performance\n",
    "\n",
    "### When to Use Extended Thinking:\n",
    "✅ Complex mathematical problems  \n",
    "✅ Multi-step reasoning tasks  \n",
    "✅ Algorithm design and optimization  \n",
    "✅ Deep analysis requiring systematic approach  \n",
    "✅ Problems benefiting from transparent reasoning  \n",
    "\n",
    "### When NOT to Use Extended Thinking:\n",
    "❌ Simple factual queries  \n",
    "❌ Basic text generation  \n",
    "❌ Tasks where speed is critical  \n",
    "❌ When you need deterministic outputs (thinking adds variability)  \n",
    "\n",
    "---\n",
    "\n",
    "**Reference**: This notebook is based on [Anthropic's Extended Thinking documentation](https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}