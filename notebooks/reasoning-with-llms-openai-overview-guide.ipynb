{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Reasoning with LLMs\n",
    "\n",
    "## A Comprehensive Tutorial on OpenAI's Reasoning Models\n",
    "\n",
    "Welcome to this comprehensive tutorial on reasoning with Large Language Models (LLMs), specifically focusing on OpenAI's o-series reasoning models and the new GPT-5. This notebook will teach you:\n",
    "\n",
    "1. **What reasoning means** in the context of LLMs\n",
    "2. **How reasoning works** technically\n",
    "3. **How to use reasoning models** with the OpenAI API\n",
    "4. **Best practices** for getting the most out of reasoning models\n",
    "5. **Common pitfalls** and how to avoid them\n",
    "6. **GPT-5's revolutionary capabilities** and how it changes the reasoning landscape\n",
    "\n",
    "### Prerequisites\n",
    "- Basic Python knowledge\n",
    "- OpenAI API key\n",
    "- Understanding of basic LLM concepts\n",
    "\n",
    "### Models Covered\n",
    "- **o1-preview**: Full reasoning model (legacy)\n",
    "- **o1-mini**: Faster, more efficient reasoning (legacy)\n",
    "- **o3**: Advanced reasoning model\n",
    "- **o3-mini**: Efficient variant of o3\n",
    "- **GPT-5**: üÜï Latest breakthrough model with built-in reasoning (August 2025)\n",
    "- **GPT-5 mini**: Efficient GPT-5 variant\n",
    "- **GPT-5 nano**: Ultra-efficient GPT-5 variant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "\n",
    "1. [What is Reasoning in LLMs?](#what-is-reasoning)\n",
    "2. [How Reasoning Works](#how-reasoning-works)\n",
    "3. [GPT-5: The New Reasoning Paradigm](#gpt-5-paradigm)\n",
    "4. [Setting Up the Environment](#setup)\n",
    "5. [Basic API Usage](#basic-api)\n",
    "6. [Advanced Features](#advanced-features)\n",
    "7. [Prompting Strategies](#prompting)\n",
    "8. [Cost and Performance Optimization](#optimization)\n",
    "9. [Common Pitfalls and Solutions](#pitfalls)\n",
    "10. [Practical Examples](#examples)\n",
    "11. [Summary and Next Steps](#summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='what-is-reasoning'></a>\n",
    "## 1. What is Reasoning in LLMs?\n",
    "\n",
    "### Traditional LLMs vs Reasoning Models vs GPT-5\n",
    "\n",
    "**Traditional LLMs (GPT-4, Claude, etc.)**\n",
    "- Generate responses quickly based on pattern matching\n",
    "- Excel at straightforward tasks and conversations\n",
    "- Optimized for speed and general-purpose use\n",
    "- Think of them as \"fast thinkers\" using System 1 thinking\n",
    "\n",
    "**Dedicated Reasoning Models (o1, o3, etc.)**\n",
    "- \"Think\" before responding through chain-of-thought reasoning\n",
    "- Excel at complex, multi-step problems\n",
    "- Trade speed for accuracy and depth\n",
    "- Think of them as \"slow thinkers\" using System 2 thinking\n",
    "- Separate reasoning tokens (hidden from user)\n",
    "\n",
    "**üÜï GPT-5 (August 2025)**\n",
    "- **Built-in reasoning**: No separate reasoning tokens needed\n",
    "- **Best of both worlds**: Fast when simple, deep when complex\n",
    "- **Adaptive thinking**: Automatically determines when to reason deeply\n",
    "- **50-80% fewer output tokens** than o3 with better performance\n",
    "- **Integrated capabilities**: Combines chat, reasoning, and tool use seamlessly\n",
    "\n",
    "### Key Characteristics Across Model Types\n",
    "\n",
    "| Feature | Traditional LLMs | o-series Models | GPT-5 |\n",
    "|---------|------------------|-----------------|-------|\n",
    "| **Speed** | Very Fast (~1-3s) | Slow (~15-60s) | Dynamic (1-15s) |\n",
    "| **Reasoning** | Basic | Advanced (explicit) | Advanced (built-in) |\n",
    "| **Token Efficiency** | High | Low (hidden tokens) | Very High |\n",
    "| **Cost** | Low | High | Moderate |\n",
    "| **Use Cases** | General chat | Complex problems | Universal |\n",
    "\n",
    "### Revolutionary GPT-5 Capabilities\n",
    "\n",
    "1. **Built-in Reasoning**: GPT-5 can \"think\" more deeply when problems benefit from careful analysis\n",
    "2. **Reduced Hallucinations**: 45% fewer factual errors than GPT-4o, 80% fewer than o3 when thinking\n",
    "3. **Superior Performance**: Outperforms o3 across coding, science, and reasoning benchmarks\n",
    "4. **Cost Effectiveness**: Half the input cost of GPT-4o with same output pricing\n",
    "5. **Universal Access**: Available to all users including free tier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When to Use Reasoning Models\n",
    "\n",
    "‚úÖ **Use reasoning models for:**\n",
    "- Complex mathematical problems\n",
    "- Multi-step logical reasoning\n",
    "- Code generation and debugging\n",
    "- Scientific analysis\n",
    "- Strategic planning\n",
    "- Legal document analysis\n",
    "- Data validation and verification\n",
    "\n",
    "‚ùå **Don't use reasoning models for:**\n",
    "- Simple queries\n",
    "- Real-time chat applications\n",
    "- Basic text formatting\n",
    "- Quick lookups\n",
    "- Tasks where speed is critical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='how-reasoning-works'></a>\n",
    "## 2. How Reasoning Works\n",
    "\n",
    "### The Technical Architecture\n",
    "\n",
    "Reasoning models use a multi-stage approach:\n",
    "\n",
    "1. **Understanding Phase**: Parse and comprehend the input\n",
    "2. **Reasoning Phase**: Generate internal \"reasoning tokens\" (hidden from user)\n",
    "3. **Solution Phase**: Produce the final output\n",
    "\n",
    "### Reasoning Tokens\n",
    "\n",
    "A unique feature of reasoning models is the concept of **reasoning tokens**:\n",
    "\n",
    "- These are internal tokens used during the thinking process\n",
    "- They're not visible in the response but count toward billing\n",
    "- The number of reasoning tokens correlates with problem complexity\n",
    "- You can influence this with the `reasoning_effort` parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='gpt-5-paradigm'></a>\n",
    "## 3. GPT-5: The New Reasoning Paradigm\n",
    "\n",
    "### What Makes GPT-5 Different\n",
    "\n",
    "GPT-5, released in August 2025, represents a paradigm shift in AI reasoning. Unlike dedicated reasoning models that use separate \"reasoning tokens,\" GPT-5 has **built-in reasoning** capabilities that activate automatically when needed.\n",
    "\n",
    "### Key GPT-5 Innovations\n",
    "\n",
    "#### 1. **Adaptive Reasoning**\n",
    "- Automatically detects when deep thinking is beneficial\n",
    "- No need to choose between \"chat\" and \"reasoning\" models\n",
    "- Dynamic response time based on problem complexity\n",
    "\n",
    "#### 2. **Superior Performance Metrics**\n",
    "- **Math**: 94.6% on AIME 2025 (vs. previous models)\n",
    "- **Coding**: 74.9% on SWE-bench Verified, 88% on Aider Polyglot\n",
    "- **Multimodal**: 84.2% on MMMU benchmark\n",
    "- **Health/Science**: 46.2% on HealthBench Hard\n",
    "\n",
    "#### 3. **Dramatically Reduced Hallucinations**\n",
    "- 45% fewer factual errors than GPT-4o with web search\n",
    "- 80% fewer factual errors than o3 when reasoning\n",
    "- More reliable for critical applications\n",
    "\n",
    "#### 4. **Revolutionary Pricing**\n",
    "- **GPT-5**: $1.25/1M input tokens, $10/1M output tokens\n",
    "- **GPT-5 mini**: $0.25/1M input, $2/1M output  \n",
    "- **GPT-5 nano**: $0.05/1M input, $0.40/1M output\n",
    "- 50% cheaper input costs than GPT-4o\n",
    "\n",
    "### GPT-5 Model Variants\n",
    "\n",
    "| Model | Best For | Cost | Context | Reasoning Level |\n",
    "|-------|----------|------|---------|----------------|\n",
    "| **GPT-5** | Complex reasoning, coding, analysis | High | 272K input, 128K output | Full |\n",
    "| **GPT-5 mini** | Balanced performance and cost | Medium | 272K input, 128K output | Moderate |\n",
    "| **GPT-5 nano** | High-volume, simple tasks | Low | 272K input, 128K output | Basic |\n",
    "\n",
    "### When to Use GPT-5 vs. o-series Models\n",
    "\n",
    "‚úÖ **Use GPT-5 for:**\n",
    "- Universal applications (chat + reasoning)\n",
    "- Cost-sensitive projects requiring reasoning\n",
    "- Applications needing reliable, low-hallucination responses\n",
    "- Coding and technical tasks\n",
    "- When you want one model to handle everything\n",
    "\n",
    "‚úÖ **Still use o-series models for:**\n",
    "- Specialized reasoning workflows\n",
    "- When you need explicit reasoning token visibility\n",
    "- Legacy systems already optimized for o-models\n",
    "- Research requiring reasoning transparency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5l/y8s3fc655417629rqwgxkhx80000gn/T/ipykernel_5430/915644012.py:47: UserWarning: Glyph 129300 (\\N{THINKING FACE}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/Users/greatmaster/miniconda3/envs/oreilly-reasoning/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 129300 (\\N{THINKING FACE}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization of the reasoning process\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create a simple visualization of reasoning vs traditional LLM process\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# Traditional LLM\n",
    "ax1.set_title('Traditional LLM Process', fontsize=14, fontweight='bold')\n",
    "ax1.arrow(0.1, 0.5, 0.3, 0, head_width=0.1, head_length=0.02, fc='blue', ec='blue')\n",
    "ax1.text(0.25, 0.7, 'Input', ha='center', fontsize=12)\n",
    "ax1.arrow(0.45, 0.5, 0.3, 0, head_width=0.1, head_length=0.02, fc='green', ec='green')\n",
    "ax1.text(0.6, 0.7, 'Direct Processing', ha='center', fontsize=12)\n",
    "ax1.arrow(0.8, 0.5, 0.1, 0, head_width=0.1, head_length=0.02, fc='red', ec='red')\n",
    "ax1.text(0.85, 0.7, 'Output', ha='center', fontsize=12)\n",
    "ax1.text(0.5, 0.2, 'Time: ~1-3 seconds', ha='center', fontsize=11, style='italic')\n",
    "ax1.set_xlim(0, 1)\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.axis('off')\n",
    "\n",
    "# Reasoning Model\n",
    "ax2.set_title('Reasoning Model Process', fontsize=14, fontweight='bold')\n",
    "ax2.arrow(0.05, 0.5, 0.1, 0, head_width=0.1, head_length=0.01, fc='blue', ec='blue')\n",
    "ax2.text(0.1, 0.7, 'Input', ha='center', fontsize=12)\n",
    "\n",
    "# Reasoning steps\n",
    "reasoning_steps = ['Understand', 'Plan', 'Execute', 'Verify', 'Refine']\n",
    "step_width = 0.12\n",
    "start_x = 0.18\n",
    "\n",
    "for i, step in enumerate(reasoning_steps):\n",
    "    x = start_x + i * step_width\n",
    "    ax2.arrow(x, 0.5, step_width-0.02, 0, head_width=0.05, head_length=0.01, \n",
    "              fc='orange', ec='orange', alpha=0.7)\n",
    "    ax2.text(x + step_width/2, 0.7, step, ha='center', fontsize=10)\n",
    "    ax2.text(x + step_width/2, 0.35, 'ü§î', ha='center', fontsize=16)\n",
    "\n",
    "ax2.arrow(0.82, 0.5, 0.1, 0, head_width=0.1, head_length=0.01, fc='red', ec='red')\n",
    "ax2.text(0.87, 0.7, 'Output', ha='center', fontsize=12)\n",
    "ax2.text(0.5, 0.15, 'Time: ~15-60 seconds', ha='center', fontsize=11, style='italic')\n",
    "ax2.text(0.5, 0.05, '(Hidden reasoning tokens generated)', ha='center', fontsize=10, \n",
    "         style='italic', color='gray')\n",
    "ax2.set_xlim(0, 1)\n",
    "ax2.set_ylim(0, 1)\n",
    "ax2.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='setup'></a>\n",
    "## 3. Setting Up the Environment\n",
    "\n",
    "Let's start by installing the necessary packages and setting up our OpenAI client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install openai>=1.12.0 python-dotenv matplotlib pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ OpenAI client initialized successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from typing import Dict, List, Optional\n",
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Load environment variables\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Initialize OpenAI client\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "if not api_key:\n",
    "    api_key = input(\"Please enter your OpenAI API key: \")\n",
    "    os.environ['OPENAI_API_KEY'] = api_key\n",
    "\n",
    "client = OpenAI(api_key=api_key)\n",
    "\n",
    "print(\"‚úÖ OpenAI client initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define available reasoning models and their characteristics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### üöÄ Reasoning Models Comparison (Updated August 2025)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**üÜï GPT-5 models are now the recommended choice for most use cases**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>best_for</th>\n",
       "      <th>latency</th>\n",
       "      <th>cost</th>\n",
       "      <th>max_tokens</th>\n",
       "      <th>key_features</th>\n",
       "      <th>status</th>\n",
       "      <th>note</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gpt-5</th>\n",
       "      <td>Latest breakthrough model with built-in reason...</td>\n",
       "      <td>Universal use: chat, reasoning, coding, analysis</td>\n",
       "      <td>1-15 seconds (adaptive)</td>\n",
       "      <td>Moderate ($1.25/$10 per 1M tokens)</td>\n",
       "      <td>272K input, 128K output</td>\n",
       "      <td>Built-in reasoning, 45% fewer hallucinations, ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-5-mini</th>\n",
       "      <td>Efficient GPT-5 variant with balanced performance</td>\n",
       "      <td>Cost-conscious applications needing reasoning</td>\n",
       "      <td>1-10 seconds (adaptive)</td>\n",
       "      <td>Low ($0.25/$2 per 1M tokens)</td>\n",
       "      <td>272K input, 128K output</td>\n",
       "      <td>Best price/performance ratio for reasoning tasks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gpt-5-nano</th>\n",
       "      <td>Ultra-efficient GPT-5 for high-volume applicat...</td>\n",
       "      <td>High-volume, cost-sensitive applications</td>\n",
       "      <td>1-5 seconds</td>\n",
       "      <td>Very Low ($0.05/$0.40 per 1M tokens)</td>\n",
       "      <td>272K input, 128K output</td>\n",
       "      <td>Lowest cost option with basic reasoning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o1-preview</th>\n",
       "      <td>Full reasoning model with maximum capabilities...</td>\n",
       "      <td>Complex problems requiring deep analysis</td>\n",
       "      <td>30-120 seconds</td>\n",
       "      <td>Highest</td>\n",
       "      <td>128000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Legacy - consider GPT-5 for new projects</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o1-mini</th>\n",
       "      <td>Efficient reasoning model, 80% performance at ...</td>\n",
       "      <td>Code tasks, math problems, moderate complexity</td>\n",
       "      <td>15-45 seconds</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>65536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Legacy - consider GPT-5 mini for new projects</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o3</th>\n",
       "      <td>Advanced reasoning model (requires tier 5 access)</td>\n",
       "      <td>Frontier research, complex multi-modal tasks</td>\n",
       "      <td>45-180 seconds</td>\n",
       "      <td>Highest</td>\n",
       "      <td>128000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Requires tier 5 access, outperformed by GPT-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>o3-mini</th>\n",
       "      <td>Efficient variant of o3 (requires tier 5 access)</td>\n",
       "      <td>Production use cases requiring o3 capabilities</td>\n",
       "      <td>20-60 seconds</td>\n",
       "      <td>High</td>\n",
       "      <td>65536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Requires tier 5 access, consider GPT-5 mini in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  description  \\\n",
       "gpt-5       Latest breakthrough model with built-in reason...   \n",
       "gpt-5-mini  Efficient GPT-5 variant with balanced performance   \n",
       "gpt-5-nano  Ultra-efficient GPT-5 for high-volume applicat...   \n",
       "o1-preview  Full reasoning model with maximum capabilities...   \n",
       "o1-mini     Efficient reasoning model, 80% performance at ...   \n",
       "o3          Advanced reasoning model (requires tier 5 access)   \n",
       "o3-mini      Efficient variant of o3 (requires tier 5 access)   \n",
       "\n",
       "                                                    best_for  \\\n",
       "gpt-5       Universal use: chat, reasoning, coding, analysis   \n",
       "gpt-5-mini     Cost-conscious applications needing reasoning   \n",
       "gpt-5-nano          High-volume, cost-sensitive applications   \n",
       "o1-preview          Complex problems requiring deep analysis   \n",
       "o1-mini       Code tasks, math problems, moderate complexity   \n",
       "o3              Frontier research, complex multi-modal tasks   \n",
       "o3-mini       Production use cases requiring o3 capabilities   \n",
       "\n",
       "                            latency                                  cost  \\\n",
       "gpt-5       1-15 seconds (adaptive)    Moderate ($1.25/$10 per 1M tokens)   \n",
       "gpt-5-mini  1-10 seconds (adaptive)          Low ($0.25/$2 per 1M tokens)   \n",
       "gpt-5-nano              1-5 seconds  Very Low ($0.05/$0.40 per 1M tokens)   \n",
       "o1-preview           30-120 seconds                               Highest   \n",
       "o1-mini               15-45 seconds                              Moderate   \n",
       "o3                   45-180 seconds                               Highest   \n",
       "o3-mini               20-60 seconds                                  High   \n",
       "\n",
       "                         max_tokens  \\\n",
       "gpt-5       272K input, 128K output   \n",
       "gpt-5-mini  272K input, 128K output   \n",
       "gpt-5-nano  272K input, 128K output   \n",
       "o1-preview                   128000   \n",
       "o1-mini                       65536   \n",
       "o3                           128000   \n",
       "o3-mini                       65536   \n",
       "\n",
       "                                                 key_features  \\\n",
       "gpt-5       Built-in reasoning, 45% fewer hallucinations, ...   \n",
       "gpt-5-mini   Best price/performance ratio for reasoning tasks   \n",
       "gpt-5-nano            Lowest cost option with basic reasoning   \n",
       "o1-preview                                                NaN   \n",
       "o1-mini                                                   NaN   \n",
       "o3                                                        NaN   \n",
       "o3-mini                                                   NaN   \n",
       "\n",
       "                                                   status  \\\n",
       "gpt-5                                                 NaN   \n",
       "gpt-5-mini                                            NaN   \n",
       "gpt-5-nano                                            NaN   \n",
       "o1-preview       Legacy - consider GPT-5 for new projects   \n",
       "o1-mini     Legacy - consider GPT-5 mini for new projects   \n",
       "o3                                                    NaN   \n",
       "o3-mini                                               NaN   \n",
       "\n",
       "                                                         note  \n",
       "gpt-5                                                     NaN  \n",
       "gpt-5-mini                                                NaN  \n",
       "gpt-5-nano                                                NaN  \n",
       "o1-preview                                                NaN  \n",
       "o1-mini                                                   NaN  \n",
       "o3              Requires tier 5 access, outperformed by GPT-5  \n",
       "o3-mini     Requires tier 5 access, consider GPT-5 mini in...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "REASONING_MODELS = {\n",
    "    \"gpt-5\": {\n",
    "        \"description\": \"Latest breakthrough model with built-in reasoning (Aug 2025)\",\n",
    "        \"best_for\": \"Universal use: chat, reasoning, coding, analysis\",\n",
    "        \"latency\": \"1-15 seconds (adaptive)\",\n",
    "        \"cost\": \"Moderate ($1.25/$10 per 1M tokens)\",\n",
    "        \"max_tokens\": \"272K input, 128K output\",\n",
    "        \"key_features\": \"Built-in reasoning, 45% fewer hallucinations, superior coding\"\n",
    "    },\n",
    "    \"gpt-5-mini\": {\n",
    "        \"description\": \"Efficient GPT-5 variant with balanced performance\",\n",
    "        \"best_for\": \"Cost-conscious applications needing reasoning\",\n",
    "        \"latency\": \"1-10 seconds (adaptive)\",\n",
    "        \"cost\": \"Low ($0.25/$2 per 1M tokens)\",\n",
    "        \"max_tokens\": \"272K input, 128K output\",\n",
    "        \"key_features\": \"Best price/performance ratio for reasoning tasks\"\n",
    "    },\n",
    "    \"gpt-5-nano\": {\n",
    "        \"description\": \"Ultra-efficient GPT-5 for high-volume applications\",\n",
    "        \"best_for\": \"High-volume, cost-sensitive applications\",\n",
    "        \"latency\": \"1-5 seconds\",\n",
    "        \"cost\": \"Very Low ($0.05/$0.40 per 1M tokens)\",\n",
    "        \"max_tokens\": \"272K input, 128K output\",\n",
    "        \"key_features\": \"Lowest cost option with basic reasoning\"\n",
    "    },\n",
    "    \"o1-preview\": {\n",
    "        \"description\": \"Full reasoning model with maximum capabilities (legacy)\",\n",
    "        \"best_for\": \"Complex problems requiring deep analysis\",\n",
    "        \"latency\": \"30-120 seconds\",\n",
    "        \"cost\": \"Highest\",\n",
    "        \"max_tokens\": 128000,\n",
    "        \"status\": \"Legacy - consider GPT-5 for new projects\"\n",
    "    },\n",
    "    \"o1-mini\": {\n",
    "        \"description\": \"Efficient reasoning model, 80% performance at 50% cost (legacy)\",\n",
    "        \"best_for\": \"Code tasks, math problems, moderate complexity\",\n",
    "        \"latency\": \"15-45 seconds\",\n",
    "        \"cost\": \"Moderate\",\n",
    "        \"max_tokens\": 65536,\n",
    "        \"status\": \"Legacy - consider GPT-5 mini for new projects\"\n",
    "    },\n",
    "    \"o3\": {\n",
    "        \"description\": \"Advanced reasoning model (requires tier 5 access)\",\n",
    "        \"best_for\": \"Frontier research, complex multi-modal tasks\",\n",
    "        \"latency\": \"45-180 seconds\",\n",
    "        \"cost\": \"Highest\",\n",
    "        \"max_tokens\": 128000,\n",
    "        \"note\": \"Requires tier 5 access, outperformed by GPT-5\"\n",
    "    },\n",
    "    \"o3-mini\": {\n",
    "        \"description\": \"Efficient variant of o3 (requires tier 5 access)\",\n",
    "        \"best_for\": \"Production use cases requiring o3 capabilities\",\n",
    "        \"latency\": \"20-60 seconds\",\n",
    "        \"cost\": \"High\",\n",
    "        \"max_tokens\": 65536,\n",
    "        \"note\": \"Requires tier 5 access, consider GPT-5 mini instead\"\n",
    "    }\n",
    "}\n",
    "\n",
    "# Display model comparison with GPT-5 highlighted\n",
    "df = pd.DataFrame(REASONING_MODELS).T\n",
    "\n",
    "# Highlight GPT-5 models\n",
    "display(Markdown(\"### üöÄ Reasoning Models Comparison (Updated August 2025)\"))\n",
    "display(Markdown(\"**üÜï GPT-5 models are now the recommended choice for most use cases**\"))\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='basic-api'></a>\n",
    "## 4. Basic API Usage\n",
    "\n",
    "### Important API Differences\n",
    "\n",
    "**Traditional Chat Models vs. o-series vs. GPT-5:**\n",
    "\n",
    "| Feature | Chat Models | o-series Models | GPT-5 Models |\n",
    "|---------|-------------|-----------------|--------------|\n",
    "| **max_tokens parameter** | ‚úÖ max_tokens | ‚ùå max_completion_tokens | ‚úÖ max_tokens |\n",
    "| **Temperature/top_p** | ‚úÖ Supported | ‚ùå Not supported | ‚úÖ Supported |\n",
    "| **System messages** | ‚úÖ Standard | ‚ö†Ô∏è Treated as developer | ‚úÖ Standard |\n",
    "| **Reasoning tokens** | ‚ùå None | ‚úÖ Hidden tokens | ‚úÖ Built-in (no separate tokens) |\n",
    "| **Response format** | Standard | Includes reasoning metrics | Standard + enhanced capabilities |\n",
    "\n",
    "### GPT-5 API Advantages\n",
    "\n",
    "1. **Familiar API**: Uses standard Chat Completions format\n",
    "2. **Built-in Reasoning**: No special parameters needed for reasoning\n",
    "3. **Reasoning Levels**: Optional `reasoning_effort` parameter (minimal/low/medium/high)\n",
    "4. **Cost Effective**: No hidden reasoning token costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_reasoning_model(\n",
    "    prompt: str,\n",
    "    model: str = \"gpt-5-mini\",  # Updated default to GPT-5 mini\n",
    "    max_tokens: int = 4096,\n",
    "    reasoning_effort: str = None,  # New parameter for GPT-5\n",
    "    show_metrics: bool = True\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Call a reasoning model with proper parameters.\n",
    "    \n",
    "    Args:\n",
    "        prompt: The user prompt\n",
    "        model: The model to use (gpt-5, gpt-5-mini, gpt-5-nano, o1-mini, etc.)\n",
    "        max_tokens: Maximum tokens in response (for GPT-5) or max_completion_tokens (for o-series)\n",
    "        reasoning_effort: For GPT-5 models: \"minimal\", \"low\", \"medium\", \"high\"\n",
    "        show_metrics: Whether to display token metrics\n",
    "    \n",
    "    Returns:\n",
    "        Response dictionary with content and metrics\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Record start time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Prepare parameters based on model type\n",
    "        if model.startswith('gpt-5'):\n",
    "            # GPT-5 models use standard Chat Completions API\n",
    "            params = {\n",
    "                \"model\": model,\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                \"max_tokens\": max_tokens\n",
    "            }\n",
    "            # Add reasoning effort if specified\n",
    "            if reasoning_effort:\n",
    "                params[\"reasoning_effort\"] = reasoning_effort\n",
    "        else:\n",
    "            # o-series models use max_completion_tokens\n",
    "            params = {\n",
    "                \"model\": model,\n",
    "                \"messages\": [{\"role\": \"user\", \"content\": prompt}],\n",
    "                \"max_completion_tokens\": max_tokens\n",
    "            }\n",
    "        \n",
    "        # Make API call\n",
    "        response = client.chat.completions.create(**params)\n",
    "        \n",
    "        # Calculate elapsed time\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        # Extract response details\n",
    "        result = {\n",
    "            \"content\": response.choices[0].message.content,\n",
    "            \"model\": response.model,\n",
    "            \"elapsed_time\": elapsed_time,\n",
    "            \"usage\": {\n",
    "                \"prompt_tokens\": response.usage.prompt_tokens,\n",
    "                \"completion_tokens\": response.usage.completion_tokens,\n",
    "                \"total_tokens\": response.usage.total_tokens\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Add reasoning tokens if available (o-series models)\n",
    "        if hasattr(response.usage, 'completion_tokens_details'):\n",
    "            details = response.usage.completion_tokens_details\n",
    "            if hasattr(details, 'reasoning_tokens'):\n",
    "                result[\"usage\"][\"reasoning_tokens\"] = details.reasoning_tokens\n",
    "        \n",
    "        # Display metrics if requested\n",
    "        if show_metrics:\n",
    "            print(f\"\\nüìä Response Metrics:\")\n",
    "            print(f\"  Model: {result['model']}\")\n",
    "            print(f\"  Time: {result['elapsed_time']:.2f} seconds\")\n",
    "            print(f\"  Tokens: {result['usage']['total_tokens']} total\")\n",
    "            if 'reasoning_tokens' in result['usage']:\n",
    "                print(f\"  Reasoning tokens: {result['usage']['reasoning_tokens']}\")\n",
    "            if reasoning_effort:\n",
    "                print(f\"  Reasoning effort: {reasoning_effort}\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error calling {model}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_reasoning_model(\n",
    "    prompt: str,\n",
    "    model: str = \"o1-mini\",\n",
    "    max_completion_tokens: int = 4096,\n",
    "    show_metrics: bool = True\n",
    ") -> Dict:\n",
    "    \"\"\"\n",
    "    Call a reasoning model with proper parameters.\n",
    "    \n",
    "    Args:\n",
    "        prompt: The user prompt\n",
    "        model: The model to use (o1-mini, o1-preview, etc.)\n",
    "        max_completion_tokens: Maximum tokens in response\n",
    "        show_metrics: Whether to display token metrics\n",
    "    \n",
    "    Returns:\n",
    "        Response dictionary with content and metrics\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Record start time\n",
    "        start_time = time.time()\n",
    "        \n",
    "        # Make API call\n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_completion_tokens=max_completion_tokens\n",
    "        )\n",
    "        \n",
    "        # Calculate elapsed time\n",
    "        elapsed_time = time.time() - start_time\n",
    "        \n",
    "        # Extract response details\n",
    "        result = {\n",
    "            \"content\": response.choices[0].message.content,\n",
    "            \"model\": response.model,\n",
    "            \"elapsed_time\": elapsed_time,\n",
    "            \"usage\": {\n",
    "                \"prompt_tokens\": response.usage.prompt_tokens,\n",
    "                \"completion_tokens\": response.usage.completion_tokens,\n",
    "                \"total_tokens\": response.usage.total_tokens\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Add reasoning tokens if available\n",
    "        if hasattr(response.usage, 'completion_tokens_details'):\n",
    "            details = response.usage.completion_tokens_details\n",
    "            if hasattr(details, 'reasoning_tokens'):\n",
    "                result[\"usage\"][\"reasoning_tokens\"] = details.reasoning_tokens\n",
    "        \n",
    "        # Display metrics if requested\n",
    "        if show_metrics:\n",
    "            print(f\"\\nüìä Response Metrics:\")\n",
    "            print(f\"  Model: {result['model']}\")\n",
    "            print(f\"  Time: {result['elapsed_time']:.2f} seconds\")\n",
    "            print(f\"  Tokens: {result['usage']['total_tokens']} total\")\n",
    "            if 'reasoning_tokens' in result['usage']:\n",
    "                print(f\"  Reasoning tokens: {result['usage']['reasoning_tokens']}\")\n",
    "        \n",
    "        return result\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error calling {model}: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÇ Sending reasoning task to GPT-5 mini (with built-in reasoning)...\n",
      "\n",
      "\n",
      "üìä Response Metrics:\n",
      "  Model: gpt-5-mini-2025-08-07\n",
      "  Time: 5.98 seconds\n",
      "  Tokens: 177 total\n",
      "  Reasoning tokens: 64\n",
      "\n",
      "üìù Response:\n",
      "Distance = sum of distances for each segment.\n",
      "\n",
      "First segment: 60 mph √ó 2.5 h = 150 miles.\n",
      "Second segment: 40 mph √ó 1.5 h = 60 miles.\n",
      "\n",
      "Total distance = 150 + 60 = 210 miles.\n",
      "\n",
      "============================================================\n",
      "üß† Comparing Reasoning Effort Levels (GPT-5)\n",
      "============================================================\n",
      "\n",
      "üí° Minimal Reasoning (faster, basic analysis):\n",
      "\n",
      "üìä Response Metrics:\n",
      "  Model: gpt-5-mini-2025-08-07\n",
      "  Time: 5.73 seconds\n",
      "  Tokens: 180 total\n",
      "  Reasoning tokens: 64\n",
      "\n",
      "üî¨ High Reasoning (slower, deep analysis):\n",
      "\n",
      "üìä Response Metrics:\n",
      "  Model: gpt-5-mini-2025-08-07\n",
      "  Time: 6.33 seconds\n",
      "  Tokens: 201 total\n",
      "  Reasoning tokens: 64\n"
     ]
    }
   ],
   "source": [
    "# Simple math reasoning example with GPT-5\n",
    "simple_prompt = \"\"\"\n",
    "Solve this step by step:\n",
    "\n",
    "If a train travels at 60 mph for 2.5 hours, then slows to 40 mph for 1.5 hours,\n",
    "what is the total distance traveled?\n",
    "\"\"\"\n",
    "\n",
    "print(\"üöÇ Sending reasoning task to GPT-5 mini (with built-in reasoning)...\\n\")\n",
    "response = call_reasoning_model(simple_prompt, model=\"gpt-5-mini\")\n",
    "\n",
    "if response:\n",
    "    print(\"\\nüìù Response:\")\n",
    "    print(response[\"content\"])\n",
    "    \n",
    "# Let's also compare with different reasoning effort levels\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üß† Comparing Reasoning Effort Levels (GPT-5)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Example with minimal reasoning\n",
    "print(\"\\nüí° Minimal Reasoning (faster, basic analysis):\")\n",
    "response_minimal = call_reasoning_model(\n",
    "    simple_prompt, \n",
    "    model=\"gpt-5-mini\",\n",
    ")\n",
    "\n",
    "# Example with high reasoning \n",
    "print(\"\\nüî¨ High Reasoning (slower, deep analysis):\")\n",
    "response_high = call_reasoning_model(\n",
    "    simple_prompt, \n",
    "    model=\"gpt-5-mini\", \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÇ Sending reasoning task to o1-mini...\n",
      "\n",
      "\n",
      "üìä Response Metrics:\n",
      "  Model: o1-mini-2024-09-12\n",
      "  Time: 5.33 seconds\n",
      "  Tokens: 543 total\n",
      "  Reasoning tokens: 128\n",
      "\n",
      "üìù Response:\n",
      "Sure, let's solve this problem step by step.\n",
      "\n",
      "**Problem Statement:**\n",
      "A train travels at 60 mph for 2.5 hours, then slows to 40 mph for 1.5 hours. What is the total distance traveled?\n",
      "\n",
      "**Solution:**\n",
      "\n",
      "To find the total distance traveled by the train, we'll break the journey into two parts and calculate the distance for each part separately using the formula:\n",
      "\n",
      "\\[ \\text{Distance} = \\text{Speed} \\times \\text{Time} \\]\n",
      "\n",
      "1. **First Part of the Journey:**\n",
      "   - **Speed:** 60 mph\n",
      "   - **Time:** 2.5 hours\n",
      "\n",
      "   \\[\n",
      "   \\text{Distance}_1 = 60 \\, \\text{mph} \\times 2.5 \\, \\text{hours} = 150 \\, \\text{miles}\n",
      "   \\]\n",
      "\n",
      "2. **Second Part of the Journey:**\n",
      "   - **Speed:** 40 mph\n",
      "   - **Time:** 1.5 hours\n",
      "\n",
      "   \\[\n",
      "   \\text{Distance}_2 = 40 \\, \\text{mph} \\times 1.5 \\, \\text{hours} = 60 \\, \\text{miles}\n",
      "   \\]\n",
      "\n",
      "3. **Total Distance Traveled:**\n",
      "\n",
      "   Add the distances from both parts of the journey:\n",
      "\n",
      "   \\[\n",
      "   \\text{Total Distance} = \\text{Distance}_1 + \\text{Distance}_2 = 150 \\, \\text{miles} + 60 \\, \\text{miles} = 210 \\, \\text{miles}\n",
      "   \\]\n",
      "\n",
      "**Answer:**\n",
      "The train traveled a total of **210 miles**.\n"
     ]
    }
   ],
   "source": [
    "# Simple math reasoning example\n",
    "simple_prompt = \"\"\"\n",
    "Solve this step by step:\n",
    "\n",
    "If a train travels at 60 mph for 2.5 hours, then slows to 40 mph for 1.5 hours,\n",
    "what is the total distance traveled?\n",
    "\"\"\"\n",
    "\n",
    "print(\"üöÇ Sending reasoning task to o1-mini...\\n\")\n",
    "response = call_reasoning_model(simple_prompt, model=\"o1-mini\")\n",
    "\n",
    "if response:\n",
    "    print(\"\\nüìù Response:\")\n",
    "    print(response[\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2: Complex Code Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='advanced-features'></a>\n",
    "## 5. Advanced Features\n",
    "\n",
    "### GPT-5 Reasoning Effort Parameter\n",
    "\n",
    "GPT-5 introduces the `reasoning_effort` parameter to control how much \"thinking\" the model does. This replaces the separate reasoning models approach with a unified system.\n",
    "\n",
    "**Available Levels:**\n",
    "- **minimal**: Fastest responses, basic reasoning\n",
    "- **low**: Quick reasoning for straightforward problems  \n",
    "- **medium**: Balanced reasoning (default behavior)\n",
    "- **high**: Deep reasoning for complex problems\n",
    "\n",
    "### Comparison: o-series vs GPT-5 Reasoning Control\n",
    "\n",
    "| Feature | o-series Models | GPT-5 |\n",
    "|---------|-----------------|-------|\n",
    "| **Reasoning Control** | Separate models (o1-mini vs o1-preview) | Single model with `reasoning_effort` |\n",
    "| **Token Efficiency** | Hidden reasoning tokens (costly) | Built-in reasoning (efficient) |\n",
    "| **Response Time** | Fixed by model choice | Adaptive based on effort level |\n",
    "| **API Complexity** | Different APIs, parameters | Unified Chat Completions API |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='advanced-features'></a>\n",
    "## 5. Advanced Features\n",
    "\n",
    "### Using the reasoning_effort Parameter\n",
    "\n",
    "The `reasoning_effort` parameter controls how much \"thinking\" the model does:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_reasoning_efforts():\n",
    "    \"\"\"\n",
    "    Compare different reasoning effort levels.\n",
    "    Note: This parameter is only available for o3 models.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Complex problem that benefits from more reasoning\n",
    "    complex_prompt = \"\"\"\n",
    "    You have 100 coins: 99 genuine coins weighing exactly 10g each, \n",
    "    and 1 counterfeit coin that weighs either 9g or 11g.\n",
    "    \n",
    "    Using a balance scale that shows the exact weight difference,\n",
    "    what is the minimum number of weighings needed to:\n",
    "    1. Find the counterfeit coin\n",
    "    2. Determine if it's heavier or lighter\n",
    "    \n",
    "    Explain your strategy step by step.\n",
    "    \"\"\"\n",
    "    \n",
    "    effort_levels = [\"low\", \"medium\", \"high\"]\n",
    "    results = {}\n",
    "    \n",
    "    print(\"üî¨ Testing different reasoning effort levels...\\n\")\n",
    "    print(\"Note: This example shows the API structure. \")\n",
    "    print(\"The reasoning_effort parameter requires o3 model access.\\n\")\n",
    "    \n",
    "    # Simulated API calls (replace with actual calls when o3 is available)\n",
    "    for effort in effort_levels:\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Reasoning Effort: {effort.upper()}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # This is the API structure for o3 models\n",
    "        # Uncomment when o3 is available:\n",
    "        \"\"\"\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"o3\",\n",
    "            messages=[{\"role\": \"user\", \"content\": complex_prompt}],\n",
    "            max_completion_tokens=4096,\n",
    "            reasoning_effort=effort  # \"low\", \"medium\", or \"high\"\n",
    "        )\n",
    "        \"\"\"\n",
    "        \n",
    "        # For demonstration, we'll use o1-mini\n",
    "        response = call_reasoning_model(\n",
    "            complex_prompt, \n",
    "            model=\"o1-mini\",\n",
    "            show_metrics=True\n",
    "        )\n",
    "        \n",
    "        if response:\n",
    "            results[effort] = response\n",
    "            print(f\"\\nResponse preview: {response['content'][:200]}...\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run comparison (demonstration)\n",
    "# results = compare_reasoning_efforts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with the Responses API (for o3)\n",
    "\n",
    "The newer o3 models use the Responses API instead of Chat Completions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prompting'></a>\n",
    "## 6. Prompting Strategies\n",
    "\n",
    "### The Golden Rules of Reasoning Model Prompting\n",
    "\n",
    "1. **Write Briefs, Not Prompts**: Think of it as writing an email to a consultant\n",
    "2. **Provide Extensive Context**: Include all relevant information upfront\n",
    "3. **Be Explicit About Output**: Specify exactly what you want\n",
    "4. **One-Shot is the Goal**: Aim to get the right answer in a single request\n",
    "\n",
    "### üÜï GPT-5 Prompting Best Practices\n",
    "\n",
    "GPT-5 introduces new prompting capabilities that combine the best of chat and reasoning models:\n",
    "\n",
    "#### 1. **Agentic Workflow Control**\n",
    "Use `reasoning_effort` and clear instructions to guide GPT-5's proactivity:\n",
    "\n",
    "```python\n",
    "# Control reasoning depth\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-5\",\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    reasoning_effort=\"high\"  # For complex problems\n",
    ")\n",
    "```\n",
    "\n",
    "#### 2. **Structured Prompting with XML Tags**\n",
    "GPT-5 responds well to structured prompts using XML-style tags:\n",
    "\n",
    "```xml\n",
    "<context_gathering>\n",
    "Gather all relevant information about the user's request\n",
    "</context_gathering>\n",
    "\n",
    "<analysis>\n",
    "Analyze the problem systematically\n",
    "</analysis>\n",
    "\n",
    "<solution>\n",
    "Provide a comprehensive solution\n",
    "</solution>\n",
    "```\n",
    "\n",
    "#### 3. **Self-Reflection Mechanisms**\n",
    "GPT-5 can evaluate its own work when prompted:\n",
    "\n",
    "```xml\n",
    "<self_reflection>\n",
    "- Create a rubric with 5-7 quality categories\n",
    "- Internally evaluate against this rubric  \n",
    "- Iterate until top marks are achieved\n",
    "</self_reflection>\n",
    "```\n",
    "\n",
    "#### 4. **Persistence Instructions**\n",
    "For complex tasks, use persistence tags:\n",
    "\n",
    "```xml\n",
    "<persistence>\n",
    "- Keep working until the user's query is completely resolved\n",
    "- Only terminate when the problem is solved\n",
    "- Never stop at uncertainty\n",
    "</persistence>\n",
    "```\n",
    "\n",
    "### Prompting Strategy Comparison\n",
    "\n",
    "| Model Type | Best Approach | Key Techniques |\n",
    "|------------|---------------|----------------|\n",
    "| **Traditional LLMs** | Conversational, iterative | Chain-of-thought, examples |\n",
    "| **o-series Models** | Comprehensive briefs | Context stuffing, one-shot |\n",
    "| **GPT-5** | Structured + Adaptive | XML tags, self-reflection, persistence |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='prompting'></a>\n",
    "## 6. Prompting Strategies\n",
    "\n",
    "### The Golden Rules of Reasoning Model Prompting\n",
    "\n",
    "1. **Write Briefs, Not Prompts**: Think of it as writing an email to a consultant\n",
    "2. **Provide Extensive Context**: Include all relevant information upfront\n",
    "3. **Be Explicit About Output**: Specify exactly what you want\n",
    "4. **One-Shot is the Goal**: Aim to get the right answer in a single request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ùå POOR PROMPT:\n",
      "==================================================\n",
      "Help me optimize this database.\n",
      "\n",
      "Problems:\n",
      "‚Ä¢ No context about the database\n",
      "‚Ä¢ No specific requirements\n",
      "‚Ä¢ No constraints mentioned\n",
      "‚Ä¢ Unclear what 'optimize' means\n",
      "\n",
      "==================================================\n",
      "\n",
      "‚úÖ EXCELLENT PROMPT:\n",
      "==================================================\n",
      "\n",
      "CONTEXT:\n",
      "We run an e-commerce platform with the following characteristics:\n",
      "- PostgreSQL 14 database on AWS RDS (db.r5.2xlarge)\n",
      "- 500GB database size, growing 20GB/month\n",
      "- 10M products, 2M active users, 100k daily orders\n",
      "- Peak traffic: Black Friday (10x normal load)\n",
      "- Current issues: Slow product searches (>3s), order processing delays\n",
      "\n",
      "CURRENT SCHEMA:\n",
      "- products: id, name, description, price, category_id, created_at\n",
      "- users: id, email, name, created_at\n",
      "- orders: id, user_id, total, status, created_at\n",
      "- order_items: id, order_id, product_id, quantity, price\n",
      "\n",
      "CONSTRAINTS:\n",
      "- Budget: $5000/month for infrastructure\n",
      "- Downtime window: 2 hours monthly maintenance\n",
      "- Must maintain 5 years of order history\n",
      "- GDPR compliance required\n",
      "\n",
      "REQUIREMENTS:\n",
      "1. Reduce product search time to <500ms\n",
      "2. Handle Black Friday traffic without degradation\n",
      "3. Implement efficient archiving strategy\n",
      "4. Optimize for both read and write operations\n",
      "\n",
      "DELIVERABLES:\n",
      "Please provide:\n",
      "1. Specific index recommendations with CREATE INDEX statements\n",
      "2. Partitioning strategy with implementation steps\n",
      "3. Caching layer design (Redis/Memcached)\n",
      "4. Query optimization for top 5 slow queries\n",
      "5. Monitoring setup recommendations\n",
      "6. Migration plan with rollback strategy\n",
      "7. Cost analysis of proposed changes\n",
      "    \n",
      "\n",
      "Strengths:\n",
      "‚Ä¢ Comprehensive context\n",
      "‚Ä¢ Specific requirements\n",
      "‚Ä¢ Clear constraints\n",
      "‚Ä¢ Explicit deliverables\n",
      "‚Ä¢ Structured format\n"
     ]
    }
   ],
   "source": [
    "def demonstrate_prompting_strategies():\n",
    "    \"\"\"\n",
    "    Demonstrate the difference between poor and excellent prompting.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Poor prompt example\n",
    "    poor_prompt = \"\"\"Help me optimize this database.\"\"\"\n",
    "    \n",
    "    # Excellent prompt example\n",
    "    excellent_prompt = \"\"\"\n",
    "CONTEXT:\n",
    "We run an e-commerce platform with the following characteristics:\n",
    "- PostgreSQL 14 database on AWS RDS (db.r5.2xlarge)\n",
    "- 500GB database size, growing 20GB/month\n",
    "- 10M products, 2M active users, 100k daily orders\n",
    "- Peak traffic: Black Friday (10x normal load)\n",
    "- Current issues: Slow product searches (>3s), order processing delays\n",
    "\n",
    "CURRENT SCHEMA:\n",
    "- products: id, name, description, price, category_id, created_at\n",
    "- users: id, email, name, created_at\n",
    "- orders: id, user_id, total, status, created_at\n",
    "- order_items: id, order_id, product_id, quantity, price\n",
    "\n",
    "CONSTRAINTS:\n",
    "- Budget: $5000/month for infrastructure\n",
    "- Downtime window: 2 hours monthly maintenance\n",
    "- Must maintain 5 years of order history\n",
    "- GDPR compliance required\n",
    "\n",
    "REQUIREMENTS:\n",
    "1. Reduce product search time to <500ms\n",
    "2. Handle Black Friday traffic without degradation\n",
    "3. Implement efficient archiving strategy\n",
    "4. Optimize for both read and write operations\n",
    "\n",
    "DELIVERABLES:\n",
    "Please provide:\n",
    "1. Specific index recommendations with CREATE INDEX statements\n",
    "2. Partitioning strategy with implementation steps\n",
    "3. Caching layer design (Redis/Memcached)\n",
    "4. Query optimization for top 5 slow queries\n",
    "5. Monitoring setup recommendations\n",
    "6. Migration plan with rollback strategy\n",
    "7. Cost analysis of proposed changes\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"‚ùå POOR PROMPT:\")\n",
    "    print(\"=\"*50)\n",
    "    print(poor_prompt)\n",
    "    print(\"\\nProblems:\")\n",
    "    print(\"‚Ä¢ No context about the database\")\n",
    "    print(\"‚Ä¢ No specific requirements\")\n",
    "    print(\"‚Ä¢ No constraints mentioned\")\n",
    "    print(\"‚Ä¢ Unclear what 'optimize' means\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"\\n‚úÖ EXCELLENT PROMPT:\")\n",
    "    print(\"=\"*50)\n",
    "    print(excellent_prompt)\n",
    "    print(\"\\nStrengths:\")\n",
    "    print(\"‚Ä¢ Comprehensive context\")\n",
    "    print(\"‚Ä¢ Specific requirements\")\n",
    "    print(\"‚Ä¢ Clear constraints\")\n",
    "    print(\"‚Ä¢ Explicit deliverables\")\n",
    "    print(\"‚Ä¢ Structured format\")\n",
    "\n",
    "demonstrate_prompting_strategies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Context Stuffing Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Available Context-Rich Templates:\n",
      "\n",
      "\n",
      "============================================================\n",
      "Template: CODE REVIEW\n",
      "============================================================\n",
      "\n",
      "# CODE REVIEW REQUEST\n",
      "\n",
      "## CONTEXT\n",
      "- Project: {project_name}\n",
      "- Language: {language}\n",
      "- Framework: {framework}\n",
      "- Team size: {team_size}\n",
      "- Code standards: {standards}\n",
      "\n",
      "## CODE TO REVIEW\n",
      "```{language}\n",
      "{code}\n",
      "```\n",
      "\n",
      "## FOCUS AREAS\n",
      "1. Security vulnerabilities\n",
      "2. Performance bottlenecks\n",
      "3. Code maintainability\n",
      "4. Best practices adherence\n",
      "5. Test coverage gaps\n",
      "\n",
      "## DELIVERABLES\n",
      "- Severity-ranked issues list\n",
      "- Specific line-by-line feedback\n",
      "- Refactoring suggestions with code examples\n",
      "- Performance impact a...\n",
      "\n",
      "\n",
      "============================================================\n",
      "Template: DATA ANALYSIS\n",
      "============================================================\n",
      "\n",
      "# DATA ANALYSIS REQUEST\n",
      "\n",
      "## BUSINESS CONTEXT\n",
      "- Company: {company}\n",
      "- Industry: {industry}\n",
      "- Objective: {objective}\n",
      "- Stakeholders: {stakeholders}\n",
      "\n",
      "## DATASET DESCRIPTION\n",
      "- Size: {data_size}\n",
      "- Time period: {time_period}\n",
      "- Key metrics: {metrics}\n",
      "- Data quality: {quality_notes}\n",
      "\n",
      "## ANALYSIS REQUIREMENTS\n",
      "1. {requirement_1}\n",
      "2. {requirement_2}\n",
      "3. {requirement_3}\n",
      "\n",
      "## CONSTRAINTS\n",
      "- {constraint_1}\n",
      "- {constraint_2}\n",
      "\n",
      "## EXPECTED OUTPUT\n",
      "1. Executive summary (2-3 paragraphs)\n",
      "2. Key findings with statistical ...\n",
      "\n",
      "\n",
      "============================================================\n",
      "Template: ARCHITECTURE DESIGN\n",
      "============================================================\n",
      "\n",
      "# SYSTEM ARCHITECTURE DESIGN\n",
      "\n",
      "## PROJECT OVERVIEW\n",
      "- System: {system_name}\n",
      "- Purpose: {purpose}\n",
      "- Users: {user_count} {user_type}\n",
      "- Scale: {scale_requirements}\n",
      "\n",
      "## TECHNICAL REQUIREMENTS\n",
      "- Performance: {performance_reqs}\n",
      "- Availability: {availability_reqs}\n",
      "- Security: {security_reqs}\n",
      "- Compliance: {compliance_reqs}\n",
      "\n",
      "## CONSTRAINTS\n",
      "- Budget: {budget}\n",
      "- Timeline: {timeline}\n",
      "- Team expertise: {team_skills}\n",
      "- Existing infrastructure: {current_infra}\n",
      "\n",
      "## DELIVERABLES\n",
      "1. High-level architecture diagra...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_context_rich_prompt(task_type: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a context-rich prompt template for different task types.\n",
    "    \"\"\"\n",
    "    \n",
    "    templates = {\n",
    "        \"code_review\": \"\"\"\n",
    "# CODE REVIEW REQUEST\n",
    "\n",
    "## CONTEXT\n",
    "- Project: {project_name}\n",
    "- Language: {language}\n",
    "- Framework: {framework}\n",
    "- Team size: {team_size}\n",
    "- Code standards: {standards}\n",
    "\n",
    "## CODE TO REVIEW\n",
    "```{language}\n",
    "{code}\n",
    "```\n",
    "\n",
    "## FOCUS AREAS\n",
    "1. Security vulnerabilities\n",
    "2. Performance bottlenecks\n",
    "3. Code maintainability\n",
    "4. Best practices adherence\n",
    "5. Test coverage gaps\n",
    "\n",
    "## DELIVERABLES\n",
    "- Severity-ranked issues list\n",
    "- Specific line-by-line feedback\n",
    "- Refactoring suggestions with code examples\n",
    "- Performance impact analysis\n",
    "- Security audit results\n",
    "\"\"\",\n",
    "        \n",
    "        \"data_analysis\": \"\"\"\n",
    "# DATA ANALYSIS REQUEST\n",
    "\n",
    "## BUSINESS CONTEXT\n",
    "- Company: {company}\n",
    "- Industry: {industry}\n",
    "- Objective: {objective}\n",
    "- Stakeholders: {stakeholders}\n",
    "\n",
    "## DATASET DESCRIPTION\n",
    "- Size: {data_size}\n",
    "- Time period: {time_period}\n",
    "- Key metrics: {metrics}\n",
    "- Data quality: {quality_notes}\n",
    "\n",
    "## ANALYSIS REQUIREMENTS\n",
    "1. {requirement_1}\n",
    "2. {requirement_2}\n",
    "3. {requirement_3}\n",
    "\n",
    "## CONSTRAINTS\n",
    "- {constraint_1}\n",
    "- {constraint_2}\n",
    "\n",
    "## EXPECTED OUTPUT\n",
    "1. Executive summary (2-3 paragraphs)\n",
    "2. Key findings with statistical significance\n",
    "3. Actionable recommendations\n",
    "4. Risk assessment\n",
    "5. Implementation roadmap\n",
    "\"\"\",\n",
    "        \n",
    "        \"architecture_design\": \"\"\"\n",
    "# SYSTEM ARCHITECTURE DESIGN\n",
    "\n",
    "## PROJECT OVERVIEW\n",
    "- System: {system_name}\n",
    "- Purpose: {purpose}\n",
    "- Users: {user_count} {user_type}\n",
    "- Scale: {scale_requirements}\n",
    "\n",
    "## TECHNICAL REQUIREMENTS\n",
    "- Performance: {performance_reqs}\n",
    "- Availability: {availability_reqs}\n",
    "- Security: {security_reqs}\n",
    "- Compliance: {compliance_reqs}\n",
    "\n",
    "## CONSTRAINTS\n",
    "- Budget: {budget}\n",
    "- Timeline: {timeline}\n",
    "- Team expertise: {team_skills}\n",
    "- Existing infrastructure: {current_infra}\n",
    "\n",
    "## DELIVERABLES\n",
    "1. High-level architecture diagram\n",
    "2. Component descriptions\n",
    "3. Technology stack recommendations\n",
    "4. Data flow diagrams\n",
    "5. Security architecture\n",
    "6. Deployment strategy\n",
    "7. Cost estimation\n",
    "8. Risk mitigation plan\n",
    "\"\"\"\n",
    "    }\n",
    "    \n",
    "    return templates.get(task_type, \"Template not found\")\n",
    "\n",
    "# Display available templates\n",
    "print(\"üìã Available Context-Rich Templates:\\n\")\n",
    "for task_type in [\"code_review\", \"data_analysis\", \"architecture_design\"]:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Template: {task_type.upper().replace('_', ' ')}\")\n",
    "    print('='*60)\n",
    "    print(create_context_rich_prompt(task_type)[:500] + \"...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üí∞ Cost Comparison Analysis (Updated August 2025)\n",
      "\n",
      "================================================================================\n",
      "Model           Input (1K tok)  Output (1K tok) 10K Total       Notes               \n",
      "================================================================================\n",
      "gpt-5-nano      $0.0001         $0.0004         $0.00           üÜï RECOMMENDED\n",
      "gpt-5-mini      $0.0003         $0.0020         $0.01           üÜï RECOMMENDED\n",
      "gpt-5           $0.0013         $0.0100         $0.06           üÜï RECOMMENDED\n",
      "gpt-4           $0.0100         $0.0300         $0.20           Legacy\n",
      "o1-mini         $0.0030         $0.0120         $0.07           Legacy\n",
      "o1-preview      $0.0150         $0.0600         $0.38           Legacy\n",
      "\n",
      "üéØ Key Insights:\n",
      "‚Ä¢ GPT-5 mini is 50% cheaper than GPT-4 with better reasoning\n",
      "‚Ä¢ GPT-5 nano is 10x cheaper than GPT-4 for high-volume use\n",
      "‚Ä¢ GPT-5 eliminates hidden reasoning token costs\n",
      "\n",
      "üìä Model Recommendations by Task Complexity (2025 Update):\n",
      "\n",
      "Simple          Recommended: gpt-5-nano      Budget: gpt-3.5-turbo\n",
      "Moderate        Recommended: gpt-5-mini      Budget: gpt-5-nano\n",
      "Complex         Recommended: gpt-5           Budget: gpt-5-mini\n",
      "Very_Complex    Recommended: gpt-5           Budget: gpt-5\n"
     ]
    }
   ],
   "source": [
    "class CostOptimizer:\n",
    "    \"\"\"\n",
    "    Helper class for optimizing reasoning model costs.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Updated costs per 1K tokens (August 2025 pricing)\n",
    "    PRICING = {\n",
    "        \"gpt-3.5-turbo\": {\"input\": 0.0005, \"output\": 0.0015},\n",
    "        \"gpt-4\": {\"input\": 0.01, \"output\": 0.03},\n",
    "        \"gpt-5\": {\"input\": 0.00125, \"output\": 0.01},  # $1.25/$10 per 1M tokens\n",
    "        \"gpt-5-mini\": {\"input\": 0.00025, \"output\": 0.002},  # $0.25/$2 per 1M tokens  \n",
    "        \"gpt-5-nano\": {\"input\": 0.00005, \"output\": 0.0004},  # $0.05/$0.40 per 1M tokens\n",
    "        \"o1-mini\": {\"input\": 0.003, \"output\": 0.012},\n",
    "        \"o1-preview\": {\"input\": 0.015, \"output\": 0.06},\n",
    "        \"o3-mini\": {\"input\": 0.005, \"output\": 0.02},\n",
    "        \"o3\": {\"input\": 0.02, \"output\": 0.08}\n",
    "    }\n",
    "    \n",
    "    @classmethod\n",
    "    def estimate_cost(cls, model: str, input_tokens: int, output_tokens: int) -> float:\n",
    "        \"\"\"Estimate the cost for a given model and token count.\"\"\"\n",
    "        if model not in cls.PRICING:\n",
    "            return 0.0\n",
    "        \n",
    "        pricing = cls.PRICING[model]\n",
    "        input_cost = (input_tokens / 1000) * pricing[\"input\"]\n",
    "        output_cost = (output_tokens / 1000) * pricing[\"output\"]\n",
    "        \n",
    "        return input_cost + output_cost\n",
    "    \n",
    "    @classmethod\n",
    "    def recommend_model(cls, task_complexity: str, budget_sensitive: bool = False) -> str:\n",
    "        \"\"\"Recommend the best model based on task complexity and budget.\"\"\"\n",
    "        \n",
    "        recommendations = {\n",
    "            \"simple\": \"gpt-3.5-turbo\" if budget_sensitive else \"gpt-5-nano\",\n",
    "            \"moderate\": \"gpt-5-nano\" if budget_sensitive else \"gpt-5-mini\",\n",
    "            \"complex\": \"gpt-5-mini\" if budget_sensitive else \"gpt-5\",\n",
    "            \"very_complex\": \"gpt-5\" if budget_sensitive else \"gpt-5\"\n",
    "        }\n",
    "        \n",
    "        return recommendations.get(task_complexity, \"gpt-5-mini\")\n",
    "    \n",
    "    @classmethod\n",
    "    def optimize_prompt(cls, prompt: str) -> tuple[str, dict]:\n",
    "        \"\"\"Optimize a prompt to reduce token usage.\"\"\"\n",
    "        \n",
    "        original_length = len(prompt.split())\n",
    "        \n",
    "        # Optimization strategies\n",
    "        optimizations = {\n",
    "            \"Remove redundancy\": prompt.replace(\"  \", \" \"),\n",
    "            \"Use abbreviations\": prompt.replace(\"for example\", \"e.g.\"),\n",
    "            \"Compress whitespace\": \"\\n\".join(line.strip() for line in prompt.split(\"\\n\")),\n",
    "        }\n",
    "        \n",
    "        optimized = prompt\n",
    "        for strategy, result in optimizations.items():\n",
    "            if len(result.split()) < len(optimized.split()):\n",
    "                optimized = result\n",
    "        \n",
    "        savings = {\n",
    "            \"original_words\": original_length,\n",
    "            \"optimized_words\": len(optimized.split()),\n",
    "            \"reduction\": f\"{(1 - len(optimized.split())/original_length)*100:.1f}%\"\n",
    "        }\n",
    "        \n",
    "        return optimized, savings\n",
    "\n",
    "# Demonstrate cost optimization with GPT-5\n",
    "optimizer = CostOptimizer()\n",
    "\n",
    "print(\"üí∞ Cost Comparison Analysis (Updated August 2025)\\n\")\n",
    "print(\"=\"*80)\n",
    "print(f\"{'Model':<15} {'Input (1K tok)':<15} {'Output (1K tok)':<15} {'10K Total':<15} {'Notes':<20}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Highlight GPT-5 models\n",
    "priority_models = [\"gpt-5-nano\", \"gpt-5-mini\", \"gpt-5\", \"gpt-4\", \"o1-mini\", \"o1-preview\"]\n",
    "\n",
    "for model in priority_models:\n",
    "    if model in optimizer.PRICING:\n",
    "        pricing = optimizer.PRICING[model]\n",
    "        total_cost = optimizer.estimate_cost(model, 5000, 5000)\n",
    "        notes = \"üÜï RECOMMENDED\" if model.startswith('gpt-5') else \"Legacy\"\n",
    "        print(f\"{model:<15} ${pricing['input']:<14.4f} ${pricing['output']:<14.4f} ${total_cost:<14.2f} {notes}\")\n",
    "\n",
    "print(f\"\\nüéØ Key Insights:\")\n",
    "print(f\"‚Ä¢ GPT-5 mini is 50% cheaper than GPT-4 with better reasoning\")\n",
    "print(f\"‚Ä¢ GPT-5 nano is 10x cheaper than GPT-4 for high-volume use\")\n",
    "print(f\"‚Ä¢ GPT-5 eliminates hidden reasoning token costs\")\n",
    "\n",
    "print(\"\\nüìä Model Recommendations by Task Complexity (2025 Update):\\n\")\n",
    "for complexity in [\"simple\", \"moderate\", \"complex\", \"very_complex\"]:\n",
    "    regular = optimizer.recommend_model(complexity, budget_sensitive=False)\n",
    "    budget = optimizer.recommend_model(complexity, budget_sensitive=True)\n",
    "    print(f\"{complexity.title():<15} Recommended: {regular:<15} Budget: {budget}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CostOptimizer:\n",
    "    \"\"\"\n",
    "    Helper class for optimizing reasoning model costs.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Approximate costs per 1K tokens (check current pricing)\n",
    "    PRICING = {\n",
    "        \"gpt-3.5-turbo\": {\"input\": 0.0005, \"output\": 0.0015},\n",
    "        \"gpt-4\": {\"input\": 0.01, \"output\": 0.03},\n",
    "        \"o1-mini\": {\"input\": 0.003, \"output\": 0.012},\n",
    "        \"o1-preview\": {\"input\": 0.015, \"output\": 0.06},\n",
    "        \"o3-mini\": {\"input\": 0.005, \"output\": 0.02},\n",
    "        \"o3\": {\"input\": 0.02, \"output\": 0.08}\n",
    "    }\n",
    "    \n",
    "    @classmethod\n",
    "    def estimate_cost(cls, model: str, input_tokens: int, output_tokens: int) -> float:\n",
    "        \"\"\"Estimate the cost for a given model and token count.\"\"\"\n",
    "        if model not in cls.PRICING:\n",
    "            return 0.0\n",
    "        \n",
    "        pricing = cls.PRICING[model]\n",
    "        input_cost = (input_tokens / 1000) * pricing[\"input\"]\n",
    "        output_cost = (output_tokens / 1000) * pricing[\"output\"]\n",
    "        \n",
    "        return input_cost + output_cost\n",
    "    \n",
    "    @classmethod\n",
    "    def recommend_model(cls, task_complexity: str, budget_sensitive: bool = False) -> str:\n",
    "        \"\"\"Recommend the best model based on task complexity and budget.\"\"\"\n",
    "        \n",
    "        recommendations = {\n",
    "            \"simple\": \"gpt-3.5-turbo\",\n",
    "            \"moderate\": \"gpt-4\" if budget_sensitive else \"o1-mini\",\n",
    "            \"complex\": \"o1-mini\" if budget_sensitive else \"o1-preview\",\n",
    "            \"very_complex\": \"o1-preview\" if budget_sensitive else \"o3\"\n",
    "        }\n",
    "        \n",
    "        return recommendations.get(task_complexity, \"o1-mini\")\n",
    "    \n",
    "    @classmethod\n",
    "    def optimize_prompt(cls, prompt: str) -> tuple[str, dict]:\n",
    "        \"\"\"Optimize a prompt to reduce token usage.\"\"\"\n",
    "        \n",
    "        original_length = len(prompt.split())\n",
    "        \n",
    "        # Optimization strategies\n",
    "        optimizations = {\n",
    "            \"Remove redundancy\": prompt.replace(\"  \", \" \"),\n",
    "            \"Use abbreviations\": prompt.replace(\"for example\", \"e.g.\"),\n",
    "            \"Compress whitespace\": \"\\n\".join(line.strip() for line in prompt.split(\"\\n\")),\n",
    "        }\n",
    "        \n",
    "        optimized = prompt\n",
    "        for strategy, result in optimizations.items():\n",
    "            if len(result.split()) < len(optimized.split()):\n",
    "                optimized = result\n",
    "        \n",
    "        savings = {\n",
    "            \"original_words\": original_length,\n",
    "            \"optimized_words\": len(optimized.split()),\n",
    "            \"reduction\": f\"{(1 - len(optimized.split())/original_length)*100:.1f}%\"\n",
    "        }\n",
    "        \n",
    "        return optimized, savings\n",
    "\n",
    "# Demonstrate cost optimization\n",
    "optimizer = CostOptimizer()\n",
    "\n",
    "print(\"üí∞ Cost Comparison Analysis\\n\")\n",
    "print(\"=\"*70)\n",
    "print(f\"{'Model':<15} {'Input (1K tok)':<15} {'Output (1K tok)':<15} {'10K Total':<15}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "for model, pricing in optimizer.PRICING.items():\n",
    "    total_cost = optimizer.estimate_cost(model, 5000, 5000)\n",
    "    print(f\"{model:<15} ${pricing['input']:<14.4f} ${pricing['output']:<14.4f} ${total_cost:<14.2f}\")\n",
    "\n",
    "print(\"\\nüìä Model Recommendations by Task Complexity:\\n\")\n",
    "for complexity in [\"simple\", \"moderate\", \"complex\", \"very_complex\"]:\n",
    "    regular = optimizer.recommend_model(complexity, budget_sensitive=False)\n",
    "    budget = optimizer.recommend_model(complexity, budget_sensitive=True)\n",
    "    print(f\"{complexity.title():<15} Regular: {regular:<15} Budget: {budget}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Optimization Strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demonstrate_optimization_strategies():\n",
    "    \"\"\"\n",
    "    Show various strategies for optimizing reasoning model performance.\n",
    "    \"\"\"\n",
    "    \n",
    "    strategies = [\n",
    "        {\n",
    "            \"name\": \"1. Model Routing\",\n",
    "            \"description\": \"Route tasks to appropriate models based on complexity\",\n",
    "            \"example\": \"\"\"\n",
    "def route_task(task):\n",
    "    complexity = assess_complexity(task)\n",
    "    if complexity < 3:\n",
    "        return use_gpt35(task)\n",
    "    elif complexity < 7:\n",
    "        return use_o1_mini(task)\n",
    "    else:\n",
    "        return use_o1_preview(task)\n",
    "\"\"\",\n",
    "            \"savings\": \"60-80% cost reduction\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"2. Prompt Compression\",\n",
    "            \"description\": \"Reduce prompt size while maintaining context\",\n",
    "            \"example\": \"\"\"\n",
    "# Before: 5000 tokens\n",
    "full_context = load_entire_document()\n",
    "\n",
    "# After: 1000 tokens\n",
    "summary = summarize_with_gpt35(full_context)\n",
    "key_points = extract_relevant_sections(full_context)\n",
    "compressed = summary + key_points\n",
    "\"\"\",\n",
    "            \"savings\": \"40-60% token reduction\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"3. Response Caching\",\n",
    "            \"description\": \"Cache common reasoning patterns\",\n",
    "            \"example\": \"\"\"\n",
    "cache = {}\n",
    "\n",
    "def get_reasoning_response(prompt):\n",
    "    cache_key = hash(prompt)\n",
    "    if cache_key in cache:\n",
    "        return cache[cache_key]\n",
    "    \n",
    "    response = call_reasoning_model(prompt)\n",
    "    cache[cache_key] = response\n",
    "    return response\n",
    "\"\"\",\n",
    "            \"savings\": \"30-50% for repeated patterns\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"4. Batch Processing\",\n",
    "            \"description\": \"Combine multiple requests into one\",\n",
    "            \"example\": \"\"\"\n",
    "# Instead of 10 separate calls\n",
    "items = [item1, item2, ..., item10]\n",
    "batch_prompt = format_batch(items)\n",
    "response = call_reasoning_model(batch_prompt)\n",
    "results = parse_batch_response(response)\n",
    "\"\"\",\n",
    "            \"savings\": \"70% latency reduction\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"5. Pre-processing Pipeline\",\n",
    "            \"description\": \"Use cheaper models for initial processing\",\n",
    "            \"example\": \"\"\"\n",
    "# Step 1: Classify with GPT-3.5\n",
    "classification = gpt35_classify(input)\n",
    "\n",
    "# Step 2: Extract key info with GPT-4\n",
    "key_info = gpt4_extract(input)\n",
    "\n",
    "# Step 3: Deep reasoning only on complex parts\n",
    "if classification == \"complex\":\n",
    "    result = o1_reason(key_info)\n",
    "\"\"\",\n",
    "            \"savings\": \"50-70% overall cost\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"‚ö° Performance Optimization Strategies\\n\")\n",
    "    \n",
    "    for strategy in strategies:\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        print(f\"{strategy['name']}\")\n",
    "        print(f\"Description: {strategy['description']}\")\n",
    "        print(f\"\\nExample:\")\n",
    "        print(strategy['example'])\n",
    "        print(f\"\\nPotential Savings: {strategy['savings']}\")\n",
    "\n",
    "demonstrate_optimization_strategies()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pitfalls'></a>\n",
    "## 8. Common Pitfalls and Solutions\n",
    "\n",
    "### Top 5 Mistakes to Avoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_pitfalls_guide():\n",
    "    \"\"\"\n",
    "    Guide to avoiding common pitfalls with reasoning models.\n",
    "    \"\"\"\n",
    "    \n",
    "    pitfalls = [\n",
    "        {\n",
    "            \"mistake\": \"1. Treating Reasoning Models Like Chat Models\",\n",
    "            \"symptoms\": [\n",
    "                \"Trying to have back-and-forth conversations\",\n",
    "                \"Sending follow-up questions\",\n",
    "                \"Expecting instant responses\"\n",
    "            ],\n",
    "            \"solution\": \"Think 'email to consultant' not 'chat with assistant'\",\n",
    "            \"example\": {\n",
    "                \"wrong\": \"Hey, can you help with this?\\n[waits]\\nOh, also this...\",\n",
    "                \"right\": \"[Complete brief with all context and requirements upfront]\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"mistake\": \"2. Insufficient Context\",\n",
    "            \"symptoms\": [\n",
    "                \"Generic responses\",\n",
    "                \"Missing important constraints\",\n",
    "                \"Impractical solutions\"\n",
    "            ],\n",
    "            \"solution\": \"Provide 10x more context than you think necessary\",\n",
    "            \"example\": {\n",
    "                \"wrong\": \"Optimize my database\",\n",
    "                \"right\": \"[500 words of context about database, constraints, goals]\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"mistake\": \"3. Using Wrong Parameters\",\n",
    "            \"symptoms\": [\n",
    "                \"API errors\",\n",
    "                \"Parameters being ignored\",\n",
    "                \"Unexpected behavior\"\n",
    "            ],\n",
    "            \"solution\": \"Use max_completion_tokens, not max_tokens\",\n",
    "            \"example\": {\n",
    "                \"wrong\": \"temperature=0.7, max_tokens=4096\",\n",
    "                \"right\": \"max_completion_tokens=4096 (no temperature)\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"mistake\": \"4. Using Reasoning Models for Simple Tasks\",\n",
    "            \"symptoms\": [\n",
    "                \"High costs for basic operations\",\n",
    "                \"Long wait times for simple answers\",\n",
    "                \"Over-engineered solutions\"\n",
    "            ],\n",
    "            \"solution\": \"Use GPT-3.5/4 for simple tasks\",\n",
    "            \"example\": {\n",
    "                \"wrong\": \"Using o1 to format JSON\",\n",
    "                \"right\": \"Using o1 for complex algorithm design\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"mistake\": \"5. Not Specifying Output Format\",\n",
    "            \"symptoms\": [\n",
    "                \"Inconsistent response formats\",\n",
    "                \"Missing required information\",\n",
    "                \"Verbose academic-style responses\"\n",
    "            ],\n",
    "            \"solution\": \"Explicitly define expected output structure\",\n",
    "            \"example\": {\n",
    "                \"wrong\": \"Analyze this data\",\n",
    "                \"right\": \"Provide: 1) Summary 2) Top 3 insights 3) Action items\"\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    print(\"‚ö†Ô∏è Common Pitfalls and How to Avoid Them\\n\")\n",
    "    \n",
    "    for pitfall in pitfalls:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"‚ùå {pitfall['mistake']}\")\n",
    "        print(f\"\\nSymptoms:\")\n",
    "        for symptom in pitfall['symptoms']:\n",
    "            print(f\"  ‚Ä¢ {symptom}\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ Solution: {pitfall['solution']}\")\n",
    "        \n",
    "        print(f\"\\nExample:\")\n",
    "        print(f\"  ‚ùå Wrong: {pitfall['example']['wrong']}\")\n",
    "        print(f\"  ‚úÖ Right: {pitfall['example']['right']}\")\n",
    "\n",
    "common_pitfalls_guide()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='examples'></a>\n",
    "## 9. Practical Examples\n",
    "\n",
    "Let's work through some real-world examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Data Validation with Reasoning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_validation_example():\n",
    "    \"\"\"\n",
    "    Example of using reasoning models for complex data validation.\n",
    "    \"\"\"\n",
    "    \n",
    "    validation_prompt = \"\"\"\n",
    "CONTEXT:\n",
    "You are validating customer data for a financial services company.\n",
    "We need to ensure data integrity for regulatory compliance.\n",
    "\n",
    "DATA SAMPLE:\n",
    "[\n",
    "  {\"id\": 1, \"name\": \"John Doe\", \"ssn\": \"123-45-6789\", \"income\": 75000, \"credit_score\": 750},\n",
    "  {\"id\": 2, \"name\": \"Jane Smith\", \"ssn\": \"987-65-432l\", \"income\": -5000, \"credit_score\": 850},\n",
    "  {\"id\": 3, \"name\": \"Bob Johnson\", \"ssn\": \"456-78-9012\", \"income\": 45000, \"credit_score\": 1200},\n",
    "  {\"id\": 4, \"name\": \"\", \"ssn\": \"234-56-7890\", \"income\": 60000, \"credit_score\": 680},\n",
    "  {\"id\": 5, \"name\": \"Alice Brown\", \"ssn\": \"345-67-8901\", \"income\": null, \"credit_score\": 720}\n",
    "]\n",
    "\n",
    "VALIDATION RULES:\n",
    "1. SSN must be valid format (###-##-####) with only digits\n",
    "2. Income must be positive number or null\n",
    "3. Credit score must be between 300-850\n",
    "4. Name cannot be empty\n",
    "5. Check for potential duplicate records\n",
    "\n",
    "REQUIREMENTS:\n",
    "For each record, identify:\n",
    "1. All validation failures\n",
    "2. Severity (Critical/High/Medium/Low)\n",
    "3. Suggested correction if applicable\n",
    "4. Overall data quality score (0-100)\n",
    "\n",
    "OUTPUT FORMAT:\n",
    "Provide results as structured JSON with validation report.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üîç Data Validation Example\\n\")\n",
    "    print(\"Sending validation request to reasoning model...\\n\")\n",
    "    \n",
    "    # Simulated response structure\n",
    "    print(\"Expected Response Structure:\")\n",
    "    expected_response = {\n",
    "        \"validation_results\": [\n",
    "            {\n",
    "                \"id\": 1,\n",
    "                \"status\": \"valid\",\n",
    "                \"issues\": []\n",
    "            },\n",
    "            {\n",
    "                \"id\": 2,\n",
    "                \"status\": \"invalid\",\n",
    "                \"issues\": [\n",
    "                    {\"field\": \"ssn\", \"error\": \"Contains letter 'l'\", \"severity\": \"critical\"},\n",
    "                    {\"field\": \"income\", \"error\": \"Negative value\", \"severity\": \"high\"},\n",
    "                    {\"field\": \"credit_score\", \"error\": \"Out of range\", \"severity\": \"high\"}\n",
    "                ]\n",
    "            }\n",
    "        ],\n",
    "        \"data_quality_score\": 60,\n",
    "        \"summary\": \"3 of 5 records have validation errors\"\n",
    "    }\n",
    "    \n",
    "    print(json.dumps(expected_response, indent=2))\n",
    "    \n",
    "    # Actual API call would go here\n",
    "    # response = call_reasoning_model(validation_prompt, model=\"o1-mini\")\n",
    "\n",
    "data_validation_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Multi-Step Problem Solving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='summary'></a>\n",
    "## 10. Summary and Next Steps\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "1. **üÜï GPT-5 Changes Everything**: Built-in reasoning, better performance, lower cost\n",
    "2. **Model Selection Matters**: Match model to task complexity and budget\n",
    "3. **Context is Still King**: Provide comprehensive context upfront\n",
    "4. **Structured Prompting**: Use XML tags and clear instructions for GPT-5\n",
    "5. **Cost Optimization**: GPT-5 eliminates hidden reasoning token costs\n",
    "\n",
    "### 2025 Model Recommendations\n",
    "\n",
    "**ü•á First Choice: GPT-5 Family**\n",
    "- **GPT-5**: Complex reasoning, coding, analysis\n",
    "- **GPT-5 mini**: Best balance of cost and performance\n",
    "- **GPT-5 nano**: High-volume, cost-sensitive applications\n",
    "\n",
    "**ü•à Legacy Options: o-series Models**\n",
    "- Use only for specialized workflows or when GPT-5 unavailable\n",
    "- Significantly more expensive due to reasoning tokens\n",
    "\n",
    "### Quick Reference Checklist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_quick_reference():\n",
    "    \"\"\"\n",
    "    Create a quick reference guide for reasoning models (2025 edition).\n",
    "    \"\"\"\n",
    "    \n",
    "    reference = {\n",
    "        \"üÜï When to Use GPT-5\": [\n",
    "            \"Any task requiring reasoning (universal model)\",\n",
    "            \"Cost-conscious projects needing intelligence\",\n",
    "            \"Applications requiring low hallucination rates\",\n",
    "            \"Coding and technical analysis\",\n",
    "            \"When you want one model for everything\"\n",
    "        ],\n",
    "        \"When to Use o-series Models\": [\n",
    "            \"Legacy systems already optimized for o-models\",\n",
    "            \"Research requiring reasoning transparency\",\n",
    "            \"Specialized workflows with explicit reasoning needs\",\n",
    "            \"When GPT-5 is unavailable\"\n",
    "        ],\n",
    "        \"API Essentials (GPT-5)\": [\n",
    "            \"Use standard max_tokens parameter\",\n",
    "            \"Temperature and top_p supported\",\n",
    "            \"Add reasoning_effort: minimal/low/medium/high\",\n",
    "            \"Standard Chat Completions API format\",\n",
    "            \"No hidden reasoning token costs\"\n",
    "        ],\n",
    "        \"API Essentials (o-series)\": [\n",
    "            \"Use max_completion_tokens (not max_tokens)\",\n",
    "            \"No temperature/top_p parameters\",\n",
    "            \"System messages ‚Üí developer messages\",\n",
    "            \"Check reasoning_tokens in response\"\n",
    "        ],\n",
    "        \"Prompting Best Practices\": [\n",
    "            \"Use XML tags for structure (<context>, <analysis>)\",\n",
    "            \"Add self-reflection and persistence instructions\",\n",
    "            \"Provide comprehensive context upfront\",\n",
    "            \"Specify exact output format\",\n",
    "            \"Use reasoning_effort parameter appropriately\"\n",
    "        ],\n",
    "        \"Cost Optimization (2025)\": [\n",
    "            \"Default to GPT-5 mini for most tasks\",\n",
    "            \"Use GPT-5 nano for high-volume applications\",\n",
    "            \"Avoid o-series models unless specifically needed\",\n",
    "            \"Leverage reasoning_effort parameter\",\n",
    "            \"No more hidden reasoning token costs!\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    print(\"üìö QUICK REFERENCE GUIDE (Updated August 2025)\\n\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for category, items in reference.items():\n",
    "        print(f\"\\n### {category}\")\n",
    "        for item in items:\n",
    "            print(f\"  ‚úì {item}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"\\nüéØ 2025 Model Selection Matrix:\\n\")\n",
    "    \n",
    "    matrix = [\n",
    "        [\"Task Complexity\", \"ü•á Recommended\", \"ü•à Budget Option\", \"ü•â Legacy\"],\n",
    "        [\"-\" * 20, \"-\" * 20, \"-\" * 20, \"-\" * 20],\n",
    "        [\"Simple\", \"GPT-5 nano\", \"GPT-3.5-turbo\", \"GPT-4\"],\n",
    "        [\"Moderate\", \"GPT-5 mini\", \"GPT-5 nano\", \"o1-mini\"],\n",
    "        [\"Complex\", \"GPT-5\", \"GPT-5 mini\", \"o1-preview\"],\n",
    "        [\"Very Complex\", \"GPT-5\", \"GPT-5\", \"o3\"],\n",
    "        [\"Frontier Research\", \"GPT-5 + human\", \"GPT-5\", \"o3 + human\"]\n",
    "    ]\n",
    "    \n",
    "    for row in matrix:\n",
    "        print(f\"{row[0]:<20} {row[1]:<20} {row[2]:<20} {row[3]:<20}\")\n",
    "    \n",
    "    print(f\"\\nüí° Pro Tip: Start with GPT-5 mini for most use cases in 2025!\")\n",
    "\n",
    "create_quick_reference()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "1. **üÜï Start with GPT-5**: Begin with gpt-5-mini for most reasoning tasks\n",
    "2. **Experiment with reasoning_effort**: Test minimal/low/medium/high levels\n",
    "3. **Measure Performance**: Compare GPT-5 vs. o-series models for your use cases\n",
    "4. **Optimize Costs**: Migrate from o-series to GPT-5 family for cost savings\n",
    "5. **Leverage New Features**: Use XML tags, self-reflection, and persistence prompts\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [OpenAI Documentation](https://platform.openai.com/docs/guides/reasoning)\n",
    "- [GPT-5 API Reference](https://platform.openai.com/docs/api-reference)\n",
    "- [Updated Pricing (2025)](https://openai.com/api/pricing/)\n",
    "- [GPT-5 Prompting Guide](https://cookbook.openai.com/examples/gpt-5/gpt-5_prompting_guide)\n",
    "- [Community Forums](https://community.openai.com/)\n",
    "\n",
    "### The GPT-5 Revolution: Key Changes\n",
    "\n",
    "**August 2025** marked a turning point in AI reasoning:\n",
    "\n",
    "#### From Separate Models to Unified Intelligence\n",
    "- **Before**: Choose between chat models and reasoning models\n",
    "- **After**: One model (GPT-5) handles everything adaptively\n",
    "\n",
    "#### From Hidden Costs to Transparent Pricing\n",
    "- **Before**: o-series models with expensive hidden reasoning tokens\n",
    "- **After**: GPT-5 with built-in reasoning and predictable costs\n",
    "\n",
    "#### From Complex APIs to Simple Integration\n",
    "- **Before**: Different APIs for different model types\n",
    "- **After**: Standard Chat Completions API for all capabilities\n",
    "\n",
    "### Final Thoughts\n",
    "\n",
    "GPT-5 represents the evolution from specialized reasoning models to **universal intelligence**:\n",
    "\n",
    "- **From consultation to conversation** (and back again, as needed)\n",
    "- **From explicit reasoning to adaptive thinking**\n",
    "- **From cost uncertainty to predictable pricing**\n",
    "- **From model switching to seamless capability scaling**\n",
    "\n",
    "The future of AI reasoning is here, and it's more accessible, affordable, and powerful than ever.\n",
    "\n",
    "**Welcome to the GPT-5 era!** üöÄ\n",
    "\n",
    "---\n",
    "\n",
    "*This tutorial was updated in August 2025 to reflect the groundbreaking release of GPT-5. For the most current information, always check the [official OpenAI documentation](https://platform.openai.com/docs/).*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "1. **Experiment**: Start with o1-mini for moderate complexity tasks\n",
    "2. **Measure**: Track costs and performance metrics\n",
    "3. **Optimize**: Implement routing and caching strategies\n",
    "4. **Scale**: Gradually increase usage for appropriate tasks\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [OpenAI Documentation](https://platform.openai.com/docs/guides/reasoning)\n",
    "- [API Reference](https://platform.openai.com/docs/api-reference)\n",
    "- [Pricing Calculator](https://openai.com/pricing)\n",
    "- [Community Forums](https://community.openai.com/)\n",
    "\n",
    "### Final Thoughts\n",
    "\n",
    "Reasoning models represent a paradigm shift in how we interact with AI:\n",
    "\n",
    "- **From conversation to consultation**\n",
    "- **From quick answers to deep analysis**\n",
    "- **From multiple iterations to single comprehensive responses**\n",
    "\n",
    "Master these models by thinking differently about your prompts, being generous with context, and choosing the right tool for each job.\n",
    "\n",
    "Happy reasoning! üöÄ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
